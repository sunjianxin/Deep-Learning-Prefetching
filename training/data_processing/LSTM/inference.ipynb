{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import interactive\n",
    "interactive(True)\n",
    "%matplotlib qt\n",
    "\n",
    "\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import my_model\n",
    "from utilities import MyTrainDataSet, MyTestDataSet, load_data_2, load_test_data, min_max_scaling, normalize_one, construct_train_valid_tensor, construct_test_tensor, show_statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x mean: 0.5009409709733069 ; std: 0.2436898615684393\n",
    "y mean: 0.4416590158205868 ; std: 0.23351418998386245\n",
    "z mean: 0.48521343842977466 ; std: 0.2423616199566707"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean and std from training data set\n",
    "x_mean = 0.5009409709733069\n",
    "x_std = 0.2436898615684393\n",
    "y_mean = 0.4416590158205868\n",
    "y_std = 0.23351418998386245\n",
    "z_mean = 0.48521343842977466\n",
    "z_std = 0.2423616199566707"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5009409709733069"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"model_1600.pt\"\n",
    "input_dim = 3\n",
    "hidden_dim = 100\n",
    "layer_dim = 1\n",
    "output_dim = 3\n",
    "\n",
    "load_model = my_model.LSTMModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "load_model.load_state_dict(torch.load(PATH))\n",
    "load_model.eval()\n",
    "# mmodel = torch.load(PATH)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    load_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "min: 0.0\n",
      "max: 1.0\n",
      "mean: 0.5597830145569421\n",
      "std: 0.283736478050022\n",
      "-----------------------------\n",
      "min: -2.0556496185321183\n",
      "max: 2.0479269257023827\n",
      "mean: 0.24146282986463127\n",
      "std: 1.1643343560697774\n",
      "14950\n",
      "1950\n"
     ]
    }
   ],
   "source": [
    "train_set_x_1, test_set_x_1, train_set_y_1, test_set_y_1, train_set_z_1, test_set_z_1 = load_data_2('data_preprocessing/test_1_training_xyz.txt', 400)\n",
    "train_set_x_2, test_set_x_2, train_set_y_2, test_set_y_2, train_set_z_2, test_set_z_2 = load_data_2('data_preprocessing/test_2_training_xyz.txt', 400)\n",
    "train_set_x_3, test_set_x_3, train_set_y_3, test_set_y_3, train_set_z_3, test_set_z_3 = load_data_2('data_preprocessing/test_3_training_xyz.txt', 400)\n",
    "train_set_x_4, test_set_x_4, train_set_y_4, test_set_y_4, train_set_z_4, test_set_z_4 = load_data_2('data_preprocessing/test_4_training_xyz.txt', 400)\n",
    "train_set_x_5, test_set_x_5, train_set_y_5, test_set_y_5, train_set_z_5, test_set_z_5 = load_data_2('data_preprocessing/test_5_training_xyz.txt', 400)\n",
    "\n",
    "# do min-max-scaling for each data set\n",
    "# show_statistic(train_set_x_1)\n",
    "min_max_scaling(train_set_x_1)\n",
    "# show_statistic(train_set_x_1)\n",
    "min_max_scaling(train_set_x_2)\n",
    "min_max_scaling(train_set_x_3)\n",
    "min_max_scaling(train_set_x_4)\n",
    "min_max_scaling(train_set_x_5)\n",
    "\n",
    "min_max_scaling(test_set_x_1)\n",
    "min_max_scaling(test_set_x_2)\n",
    "min_max_scaling(test_set_x_3)\n",
    "min_max_scaling(test_set_x_4)\n",
    "min_max_scaling(test_set_x_5)\n",
    "\n",
    "min_max_scaling(train_set_y_1)\n",
    "min_max_scaling(train_set_y_2)\n",
    "min_max_scaling(train_set_y_3)\n",
    "min_max_scaling(train_set_y_4)\n",
    "min_max_scaling(train_set_y_5)\n",
    "\n",
    "min_max_scaling(test_set_y_1)\n",
    "min_max_scaling(test_set_y_2)\n",
    "min_max_scaling(test_set_y_3)\n",
    "min_max_scaling(test_set_y_4)\n",
    "min_max_scaling(test_set_y_5)\n",
    "\n",
    "min_max_scaling(train_set_z_1)\n",
    "min_max_scaling(train_set_z_2)\n",
    "min_max_scaling(train_set_z_3)\n",
    "min_max_scaling(train_set_z_4)\n",
    "min_max_scaling(train_set_z_5)\n",
    "\n",
    "min_max_scaling(test_set_z_1)\n",
    "min_max_scaling(test_set_z_2)\n",
    "min_max_scaling(test_set_z_3)\n",
    "min_max_scaling(test_set_z_4)\n",
    "min_max_scaling(test_set_z_5)\n",
    "\n",
    "show_statistic(test_set_x_1)\n",
    "# do normalization on x of validation test set\n",
    "normalize_one(test_set_x_1, x_mean, x_std)\n",
    "show_statistic(test_set_x_1)\n",
    "normalize_one(test_set_x_2, x_mean, x_std)\n",
    "normalize_one(test_set_x_3, x_mean, x_std)\n",
    "normalize_one(test_set_x_4, x_mean, x_std)\n",
    "normalize_one(test_set_x_5, x_mean, x_std)\n",
    "# do normalization on y of validation test set\n",
    "normalize_one(test_set_y_1, y_mean, y_std)\n",
    "normalize_one(test_set_y_2, y_mean, y_std)\n",
    "normalize_one(test_set_y_3, y_mean, y_std)\n",
    "normalize_one(test_set_y_4, y_mean, y_std)\n",
    "normalize_one(test_set_y_5, y_mean, y_std)\n",
    "# do normalization on z of validation test set\n",
    "normalize_one(test_set_z_1, z_mean, z_std)\n",
    "normalize_one(test_set_z_2, z_mean, z_std)\n",
    "normalize_one(test_set_z_3, z_mean, z_std)\n",
    "normalize_one(test_set_z_4, z_mean, z_std)\n",
    "normalize_one(test_set_z_5, z_mean, z_std)\n",
    "# show_statistic(train_set_x_1)\n",
    "\n",
    "window_size = 10\n",
    "train_dataset_1, train_label_1, test_dataset_1, test_label_1 = construct_train_valid_tensor(train_set_x_1,\n",
    "                                                                                           train_set_y_1,\n",
    "                                                                                           train_set_z_1,\n",
    "                                                                                           test_set_x_1,\n",
    "                                                                                           test_set_y_1,\n",
    "                                                                                           test_set_z_1,\n",
    "                                                                                           window_size)\n",
    "\n",
    "train_dataset_2, train_label_2, test_dataset_2, test_label_2 = construct_train_valid_tensor(train_set_x_2,\n",
    "                                                                                           train_set_y_2,\n",
    "                                                                                           train_set_z_2,\n",
    "                                                                                           test_set_x_2,\n",
    "                                                                                           test_set_y_2,\n",
    "                                                                                           test_set_z_2,\n",
    "                                                                                           window_size)\n",
    "\n",
    "train_dataset_3, train_label_3, test_dataset_3, test_label_3 = construct_train_valid_tensor(train_set_x_3,\n",
    "                                                                                           train_set_y_3,\n",
    "                                                                                           train_set_z_3,\n",
    "                                                                                           test_set_x_3,\n",
    "                                                                                           test_set_y_3,\n",
    "                                                                                           test_set_z_3,\n",
    "                                                                                           window_size)\n",
    "\n",
    "train_dataset_4, train_label_4, test_dataset_4, test_label_4 = construct_train_valid_tensor(train_set_x_4,\n",
    "                                                                                           train_set_y_4,\n",
    "                                                                                           train_set_z_4,\n",
    "                                                                                           test_set_x_4,\n",
    "                                                                                           test_set_y_4,\n",
    "                                                                                           test_set_z_4,\n",
    "                                                                                           window_size)\n",
    "\n",
    "train_dataset_5, train_label_5, test_dataset_5, test_label_5 = construct_train_valid_tensor(train_set_x_5,\n",
    "                                                                                           train_set_y_5,\n",
    "                                                                                           train_set_z_5,\n",
    "                                                                                           test_set_x_5,\n",
    "                                                                                           test_set_y_5,\n",
    "                                                                                           test_set_z_5,\n",
    "                                                                                           window_size)\n",
    "\n",
    "# Concatenate tensors\n",
    "train_dataset = np.concatenate((train_dataset_1,\n",
    "                                train_dataset_2,\n",
    "                                train_dataset_3,\n",
    "                                train_dataset_4,\n",
    "                                train_dataset_5), axis=0)\n",
    "train_label = np.concatenate((train_label_1,\n",
    "                              train_label_2,\n",
    "                              train_label_3,\n",
    "                              train_label_4,\n",
    "                              train_label_5), axis=0)\n",
    "test_dataset = np.concatenate((test_dataset_1,\n",
    "                               test_dataset_2,\n",
    "                               test_dataset_3,\n",
    "                               test_dataset_4,\n",
    "                               test_dataset_5), axis=0)\n",
    "test_label = np.concatenate((test_label_1,\n",
    "                             test_label_2,\n",
    "                             test_label_3,\n",
    "                             test_label_4,\n",
    "                             test_label_5), axis=0)\n",
    "\n",
    "\n",
    "train_set = MyTrainDataSet(train_dataset, train_label)\n",
    "print(len(train_set))\n",
    "valid_set = MyTestDataSet(test_dataset, test_label)\n",
    "print(len(valid_set))\n",
    "\n",
    "\n",
    "# batch_size = 30\n",
    "# batch_size = 50\n",
    "batch_size = 650\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "# keep the test data trajectory order\n",
    "test_loader = DataLoader(valid_set, batch_size=batch_size, num_workers=0) # dont shuffle test data for using continous trajectory later on\n",
    "# test_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "min: -2.0556496185321183\n",
    "max: 2.0479269257023827"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_test_set_x_1 = test_set_x_1\n",
    "valid_test_set_y_1 = test_set_y_1\n",
    "valid_test_set_z_1 = test_set_z_1\n",
    "valid_test_set_x_2 = test_set_x_2\n",
    "valid_test_set_y_2 = test_set_y_2\n",
    "valid_test_set_z_2 = test_set_z_2\n",
    "valid_test_set_x_3 = test_set_x_3\n",
    "valid_test_set_y_3 = test_set_y_3\n",
    "valid_test_set_z_3 = test_set_z_3\n",
    "valid_test_set_x_4 = test_set_x_4\n",
    "valid_test_set_y_4 = test_set_y_4\n",
    "valid_test_set_z_4 = test_set_z_4\n",
    "valid_test_set_x_5 = test_set_x_5\n",
    "valid_test_set_y_5 = test_set_y_5\n",
    "valid_test_set_z_5 = test_set_z_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0006675045297015458"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.0006675045297015458"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0006675045297015458"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.0006675045297015458"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0005966841854387894"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.0005966841854387894"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002250826083278904"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.0022626199449102082"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0022626199449102082\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<mpl_toolkits.mplot3d.art3d.Line3D at 0x7f9089586ba8>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get test results\n",
    "seq_dim = 10 # = window_size\n",
    "input_dim = 3\n",
    "# test_seq = []\n",
    "test_predd = []\n",
    "# test_gt = []\n",
    "total_test_loss = 0.0\n",
    "test_batch = 0\n",
    "for i, (seqs, labels) in enumerate(test_loader):\n",
    "    if torch.cuda.is_available():\n",
    "        seqs = Variable(seqs.view(-1, seq_dim, input_dim).cuda())\n",
    "        labels = Variable(labels.cuda())\n",
    "    else:\n",
    "        seqs = Variable(seqs.view(-1, seq_dim, input_dim))\n",
    "        \n",
    "    outputs = load_model(seqs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    total_test_loss += loss.data.item()\n",
    "    test_predd.append(outputs)\n",
    "    test_batch = i + 1\n",
    "print(total_test_loss/test_batch)\n",
    "\n",
    "for i in range(len(test_predd)):\n",
    "    if (i == 0):\n",
    "        pred = test_predd[i].cpu().detach().numpy()\n",
    "    else:\n",
    "        pred = np.append(pred, test_predd[i].cpu().detach().numpy(), axis = 0)\n",
    "        \n",
    "from mpl_toolkits import mplot3d\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "# Data for a three-dimensional line\n",
    "zline = np.linspace(0, 15, 1000)\n",
    "xline = np.sin(zline)\n",
    "yline = np.cos(zline)\n",
    "ax.plot3D(valid_test_set_x_5, valid_test_set_y_5, valid_test_set_z_5, 'gray')\n",
    "# ax.plot3D(test_set_x_1, test_set_y_1, test_set_z_1, 'red')\n",
    "# ax.plot3D(pred[390:780,0], pred[390:780,1], pred[390:780,2], 'red')\n",
    "# ax.plot3D(pred[780:1170,0], pred[780:1170,1], pred[780:1170,2], 'red')\n",
    "# x.plot3D(pred[1170:1560,0], pred[1170:1560,1], pred[1170:1560,2], 'red')\n",
    "ax.plot3D(pred[1560:1950,0], pred[1560:1950,1], pred[1560:1950,2], 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "390*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "min: -1.5190000000000001\n",
      "max: 1.41144\n",
      "mean: -0.058533702725000004\n",
      "std: 0.7861266362964188\n",
      "-----------------------------\n",
      "min: 0.0\n",
      "max: 1.0\n",
      "mean: 0.4983778194656777\n",
      "std: 0.26826232111779097\n",
      "-----------------------------\n",
      "min: 0.0\n",
      "max: 1.0\n",
      "mean: 0.4983778194656777\n",
      "std: 0.26826232111779097\n",
      "-----------------------------\n",
      "min: -2.0556496185321183\n",
      "max: 2.0479269257023827\n",
      "mean: -0.010518088406027203\n",
      "std: 1.1008349686408698\n",
      "390\n",
      "390\n",
      "390\n",
      "390\n",
      "390\n",
      "-----------------------------\n",
      "min: -2.0556496185321183\n",
      "max: 2.0479269257023827\n",
      "mean: -0.010518088406027203\n",
      "std: 1.1008349686408698\n",
      "-----------------------------\n",
      "min: -2.0556496185321183\n",
      "max: 2.0479269257023827\n",
      "mean: -0.003910799069243863\n",
      "std: 1.3327171046033424\n",
      "-----------------------------\n",
      "min: -2.0556496185321183\n",
      "max: 2.0479269257023827\n",
      "mean: -0.02591810651939787\n",
      "std: 1.1851356406826778\n",
      "-----------------------------\n",
      "min: -2.0556496185321183\n",
      "max: 2.0479269257023827\n",
      "mean: 0.03763954942048355\n",
      "std: 1.0437368311448298\n",
      "-----------------------------\n",
      "min: -2.0556496185321183\n",
      "max: 2.0479269257023827\n",
      "mean: -0.0646097030966006\n",
      "std: 1.0845074561144088\n"
     ]
    }
   ],
   "source": [
    "test_set_x_1, test_set_y_1, test_set_z_1 = load_test_data('../../../../performance_test/data/test/test_1.csv')\n",
    "test_set_x_2, test_set_y_2, test_set_z_2 = load_test_data('../../../../performance_test/data/test/test_2.csv')\n",
    "test_set_x_3, test_set_y_3, test_set_z_3 = load_test_data('../../../../performance_test/data/test/test_3.csv')\n",
    "test_set_x_4, test_set_y_4, test_set_z_4 = load_test_data('../../../../performance_test/data/test/test_4.csv')\n",
    "test_set_x_5, test_set_y_5, test_set_z_5 = load_test_data('../../../../performance_test/data/test/test_5.csv')\n",
    "\n",
    "# do min-max-scaling for each test data set\n",
    "show_statistic(test_set_x_1)\n",
    "min_max_scaling(test_set_x_1)\n",
    "show_statistic(test_set_x_1)\n",
    "min_max_scaling(test_set_x_2)\n",
    "min_max_scaling(test_set_x_3)\n",
    "min_max_scaling(test_set_x_4)\n",
    "min_max_scaling(test_set_x_5)\n",
    "\n",
    "min_max_scaling(test_set_y_1)\n",
    "min_max_scaling(test_set_y_2)\n",
    "min_max_scaling(test_set_y_3)\n",
    "min_max_scaling(test_set_y_4)\n",
    "min_max_scaling(test_set_y_5)\n",
    "\n",
    "min_max_scaling(test_set_z_1)\n",
    "min_max_scaling(test_set_z_2)\n",
    "min_max_scaling(test_set_z_3)\n",
    "min_max_scaling(test_set_z_4)\n",
    "min_max_scaling(test_set_z_5)\n",
    "\n",
    "\n",
    "show_statistic(test_set_x_1)\n",
    "# do normalization on x of validation test set\n",
    "normalize_one(test_set_x_1, x_mean, x_std)\n",
    "show_statistic(test_set_x_1)\n",
    "normalize_one(test_set_x_2, x_mean, x_std)\n",
    "normalize_one(test_set_x_3, x_mean, x_std)\n",
    "normalize_one(test_set_x_4, x_mean, x_std)\n",
    "normalize_one(test_set_x_5, x_mean, x_std)\n",
    "# do normalization on y of validation test set\n",
    "normalize_one(test_set_y_1, y_mean, y_std)\n",
    "normalize_one(test_set_y_2, y_mean, y_std)\n",
    "normalize_one(test_set_y_3, y_mean, y_std)\n",
    "normalize_one(test_set_y_4, y_mean, y_std)\n",
    "normalize_one(test_set_y_5, y_mean, y_std)\n",
    "# do normalization on z of validation test set\n",
    "normalize_one(test_set_z_1, z_mean, z_std)\n",
    "normalize_one(test_set_z_2, z_mean, z_std)\n",
    "normalize_one(test_set_z_3, z_mean, z_std)\n",
    "normalize_one(test_set_z_4, z_mean, z_std)\n",
    "normalize_one(test_set_z_5, z_mean, z_std)\n",
    "# show_statistic(train_set_x_1)\n",
    "\n",
    "\n",
    "window_size = 10\n",
    "test_dataset_1, test_label_1 = construct_test_tensor(test_set_x_1,\n",
    "                                                     test_set_y_1,\n",
    "                                                     test_set_z_1,\n",
    "                                                     window_size)\n",
    "test_dataset_2, test_label_2 = construct_test_tensor(test_set_x_2,\n",
    "                                                     test_set_y_2,\n",
    "                                                     test_set_z_2,\n",
    "                                                     window_size)\n",
    "test_dataset_3, test_label_3 = construct_test_tensor(test_set_x_3,\n",
    "                                                     test_set_y_3,\n",
    "                                                     test_set_z_3,\n",
    "                                                     window_size)\n",
    "test_dataset_4, test_label_4 = construct_test_tensor(test_set_x_4,\n",
    "                                                     test_set_y_4,\n",
    "                                                     test_set_z_4,\n",
    "                                                     window_size)\n",
    "test_dataset_5, test_label_5 = construct_test_tensor(test_set_x_5,\n",
    "                                                     test_set_y_5,\n",
    "                                                     test_set_z_5,\n",
    "                                                     window_size)\n",
    "\n",
    "test_set_1 = MyTestDataSet(test_dataset_1, test_label_1)\n",
    "test_set_2 = MyTestDataSet(test_dataset_2, test_label_2)\n",
    "test_set_3 = MyTestDataSet(test_dataset_3, test_label_3)\n",
    "test_set_4 = MyTestDataSet(test_dataset_4, test_label_4)\n",
    "test_set_5 = MyTestDataSet(test_dataset_5, test_label_5)\n",
    "print(len(test_set_1))\n",
    "print(len(test_set_2))\n",
    "print(len(test_set_3))\n",
    "print(len(test_set_4))\n",
    "print(len(test_set_5))\n",
    "show_statistic(test_set_x_1)\n",
    "show_statistic(test_set_x_2)\n",
    "show_statistic(test_set_x_3)\n",
    "show_statistic(test_set_x_4)\n",
    "show_statistic(test_set_x_5)\n",
    "\n",
    "\n",
    "batch_size = 650\n",
    "test_loader_1 = DataLoader(test_set_1, batch_size=batch_size, num_workers=0) # dont shuffle test data for using continous trajectory later on\n",
    "# test_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader_2 = DataLoader(test_set_2, batch_size=batch_size, num_workers=0) # dont shuffle test data for using continous trajectory later on\n",
    "# test_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader_3 = DataLoader(test_set_3, batch_size=batch_size, num_workers=0) # dont shuffle test data for using continous trajectory later on\n",
    "# test_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader_4 = DataLoader(test_set_4, batch_size=batch_size, num_workers=0) # dont shuffle test data for using continous trajectory later on\n",
    "# test_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader_5 = DataLoader(test_set_5, batch_size=batch_size, num_workers=0) # dont shuffle test data for using continous trajectory later on\n",
    "# test_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-----------------------------\n",
    "min: 0.0\n",
    "max: 1.0\n",
    "mean: 0.5597830145569421\n",
    "std: 0.283736478050022\n",
    "-----------------------------\n",
    "min: -2.0556496185321183\n",
    "max: 2.0479269257023827\n",
    "mean: 0.24146282986463127\n",
    "std: 1.1643343560697774"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits import mplot3d\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "# Data for a three-dimensional line\n",
    "zline = np.linspace(0, 15, 1000)\n",
    "xline = np.sin(zline)\n",
    "yline = np.cos(zline)\n",
    "# ax.plot3D(valid_test_set_x_1, valid_test_set_y_1, valid_test_set_z_1, 'gray')\n",
    "# ax.plot3D(train_set_x_, train_set_y_2, train_set_z_2, 'red')\n",
    "ax.plot3D(test_set_x_1, test_set_y_1, test_set_z_1, 'red')\n",
    "# ax.plot3D(pred[:,0], pred[:,1], pred[:,2], 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits import mplot3d\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "# Data for a three-dimensional line\n",
    "zline = np.linspace(0, 15, 1000)\n",
    "xline = np.sin(zline)\n",
    "yline = np.cos(zline)\n",
    "# ax.plot3D(valid_test_set_x_1, valid_test_set_y_1, valid_test_set_z_1, 'gray')\n",
    "# ax.plot3D(train_set_x_, train_set_y_2, train_set_z_2, 'red')\n",
    "ax.plot3D(test_set_x_2, test_set_y_2, test_set_z_2, 'red')\n",
    "# ax.plot3D(pred[:,0], pred[:,1], pred[:,2], 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits import mplot3d\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "# Data for a three-dimensional line\n",
    "zline = np.linspace(0, 15, 1000)\n",
    "xline = np.sin(zline)\n",
    "yline = np.cos(zline)\n",
    "# ax.plot3D(valid_test_set_x_1, valid_test_set_y_1, valid_test_set_z_1, 'gray')\n",
    "# ax.plot3D(train_set_x_, train_set_y_2, train_set_z_2, 'red')\n",
    "ax.plot3D(test_set_x_3, test_set_y_3, test_set_z_3, 'red')\n",
    "# ax.plot3D(pred[:,0], pred[:,1], pred[:,2], 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits import mplot3d\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "# Data for a three-dimensional line\n",
    "zline = np.linspace(0, 15, 1000)\n",
    "xline = np.sin(zline)\n",
    "yline = np.cos(zline)\n",
    "# ax.plot3D(valid_test_set_x_1, valid_test_set_y_1, valid_test_set_z_1, 'gray')\n",
    "# ax.plot3D(train_set_x_, train_set_y_2, train_set_z_2, 'red')\n",
    "ax.plot3D(test_set_x_4, test_set_y_4, test_set_z_4, 'red')\n",
    "# ax.plot3D(pred[:,0], pred[:,1], pred[:,2], 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits import mplot3d\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "# Data for a three-dimensional line\n",
    "zline = np.linspace(0, 15, 1000)\n",
    "xline = np.sin(zline)\n",
    "yline = np.cos(zline)\n",
    "# ax.plot3D(valid_test_set_x_1, valid_test_set_y_1, valid_test_set_z_1, 'gray')\n",
    "# ax.plot3D(train_set_x_, train_set_y_2, train_set_z_2, 'red')\n",
    "ax.plot3D(test_set_x_5, test_set_y_5, test_set_z_5, 'red')\n",
    "# ax.plot3D(pred[:,0], pred[:,1], pred[:,2], 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.022179659456014633"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.022179659456014633\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<mpl_toolkits.mplot3d.art3d.Line3D at 0x7f90885079e8>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get test results\n",
    "seq_dim = 10 # = window_size\n",
    "input_dim = 3\n",
    "# test_seq = []\n",
    "test_predd = []\n",
    "# test_gt = []\n",
    "total_test_loss = 0.0\n",
    "test_batch = 0\n",
    "for i, (seqs, labels) in enumerate(test_loader_1):\n",
    "    if torch.cuda.is_available():\n",
    "        seqs = Variable(seqs.view(-1, seq_dim, input_dim).cuda())\n",
    "        labels = Variable(labels.cuda())\n",
    "    else:\n",
    "        seqs = Variable(seqs.view(-1, seq_dim, input_dim))\n",
    "        \n",
    "    outputs = load_model(seqs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    total_test_loss += loss.data.item()\n",
    "    test_predd.append(outputs)\n",
    "    test_batch = i + 1\n",
    "\n",
    "print(total_test_loss/test_batch)\n",
    "\n",
    "for i in range(len(test_predd)):\n",
    "    if (i == 0):\n",
    "        pred = test_predd[i].cpu().detach().numpy()\n",
    "    else:\n",
    "        pred = np.append(pred, test_predd[i].cpu().detach().numpy(), axis = 0)\n",
    "        \n",
    "from mpl_toolkits import mplot3d\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "# Data for a three-dimensional line\n",
    "zline = np.linspace(0, 15, 1000)\n",
    "xline = np.sin(zline)\n",
    "yline = np.cos(zline)\n",
    "ax.plot3D(test_set_x_1, test_set_y_1, test_set_z_1, 'gray')\n",
    "ax.plot3D(pred[:,0], pred[:,1], pred[:,2], 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get test results\n",
    "seq_dim = 10 # = window_size\n",
    "input_dim = 3\n",
    "# test_seq = []\n",
    "test_predd = []\n",
    "# test_gt = []\n",
    "total_test_loss = 0.0\n",
    "test_batch = 0\n",
    "for i, (seqs, labels) in enumerate(test_loader_2):\n",
    "    if torch.cuda.is_available():\n",
    "        seqs = Variable(seqs.view(-1, seq_dim, input_dim).cuda())\n",
    "        labels = Variable(labels.cuda())\n",
    "    else:\n",
    "        seqs = Variable(seqs.view(-1, seq_dim, input_dim))\n",
    "        \n",
    "    outputs = load_model(seqs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    total_test_loss += loss.data.item()\n",
    "    test_predd.append(outputs)\n",
    "    test_batch = i + 1\n",
    "\n",
    "print(total_test_loss/test_batch)\n",
    "\n",
    "for i in range(len(test_predd)):\n",
    "    if (i == 0):\n",
    "        pred = test_predd[i].cpu().detach().numpy()\n",
    "    else:\n",
    "        pred = np.append(pred, test_predd[i].cpu().detach().numpy(), axis = 0)\n",
    "        \n",
    "from mpl_toolkits import mplot3d\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "# Data for a three-dimensional line\n",
    "zline = np.linspace(0, 15, 1000)\n",
    "xline = np.sin(zline)\n",
    "yline = np.cos(zline)\n",
    "ax.plot3D(test_set_x_2, test_set_y_2, test_set_z_2, 'gray')\n",
    "ax.plot3D(pred[:,0], pred[:,1], pred[:,2], 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get test results\n",
    "seq_dim = 10 # = window_size\n",
    "input_dim = 3\n",
    "# test_seq = []\n",
    "test_predd = []\n",
    "# test_gt = []\n",
    "total_test_loss = 0.0\n",
    "test_batch = 0\n",
    "for i, (seqs, labels) in enumerate(test_loader_3):\n",
    "    if torch.cuda.is_available():\n",
    "        seqs = Variable(seqs.view(-1, seq_dim, input_dim).cuda())\n",
    "        labels = Variable(labels.cuda())\n",
    "    else:\n",
    "        seqs = Variable(seqs.view(-1, seq_dim, input_dim))\n",
    "        \n",
    "    outputs = load_model(seqs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    total_test_loss += loss.data.item()\n",
    "    test_predd.append(outputs)\n",
    "    test_batch = i + 1\n",
    "\n",
    "print(total_test_loss/test_batch)\n",
    "\n",
    "for i in range(len(test_predd)):\n",
    "    if (i == 0):\n",
    "        pred = test_predd[i].cpu().detach().numpy()\n",
    "    else:\n",
    "        pred = np.append(pred, test_predd[i].cpu().detach().numpy(), axis = 0)\n",
    "        \n",
    "from mpl_toolkits import mplot3d\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "# Data for a three-dimensional line\n",
    "zline = np.linspace(0, 15, 1000)\n",
    "xline = np.sin(zline)\n",
    "yline = np.cos(zline)\n",
    "ax.plot3D(test_set_x_3, test_set_y_3, test_set_z_3, 'gray')\n",
    "ax.plot3D(pred[:,0], pred[:,1], pred[:,2], 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get test results\n",
    "seq_dim = 10 # = window_size\n",
    "input_dim = 3\n",
    "# test_seq = []\n",
    "test_predd = []\n",
    "# test_gt = []\n",
    "total_test_loss = 0.0\n",
    "test_batch = 0\n",
    "for i, (seqs, labels) in enumerate(test_loader_4):\n",
    "    if torch.cuda.is_available():\n",
    "        seqs = Variable(seqs.view(-1, seq_dim, input_dim).cuda())\n",
    "        labels = Variable(labels.cuda())\n",
    "    else:\n",
    "        seqs = Variable(seqs.view(-1, seq_dim, input_dim))\n",
    "        \n",
    "    outputs = load_model(seqs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    total_test_loss += loss.data.item()\n",
    "    test_predd.append(outputs)\n",
    "    test_batch = i + 1\n",
    "\n",
    "print(total_test_loss/test_batch)\n",
    "\n",
    "for i in range(len(test_predd)):\n",
    "    if (i == 0):\n",
    "        pred = test_predd[i].cpu().detach().numpy()\n",
    "    else:\n",
    "        pred = np.append(pred, test_predd[i].cpu().detach().numpy(), axis = 0)\n",
    "        \n",
    "from mpl_toolkits import mplot3d\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "# Data for a three-dimensional line\n",
    "zline = np.linspace(0, 15, 1000)\n",
    "xline = np.sin(zline)\n",
    "yline = np.cos(zline)\n",
    "ax.plot3D(test_set_x_4, test_set_y_4, test_set_z_4, 'gray')\n",
    "ax.plot3D(pred[:,0], pred[:,1], pred[:,2], 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get test results\n",
    "seq_dim = 10 # = window_size\n",
    "input_dim = 3\n",
    "# test_seq = []\n",
    "test_predd = []\n",
    "# test_gt = []\n",
    "total_test_loss = 0.0\n",
    "test_batch = 0\n",
    "for i, (seqs, labels) in enumerate(test_loader_5):\n",
    "    if torch.cuda.is_available():\n",
    "        seqs = Variable(seqs.view(-1, seq_dim, input_dim).cuda())\n",
    "        labels = Variable(labels.cuda())\n",
    "    else:\n",
    "        seqs = Variable(seqs.view(-1, seq_dim, input_dim))\n",
    "        \n",
    "    outputs = load_model(seqs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    total_test_loss += loss.data.item()\n",
    "    test_predd.append(outputs)\n",
    "    test_batch = i + 1\n",
    "\n",
    "print(total_test_loss/test_batch)\n",
    "\n",
    "for i in range(len(test_predd)):\n",
    "    if (i == 0):\n",
    "        pred = test_predd[i].cpu().detach().numpy()\n",
    "    else:\n",
    "        pred = np.append(pred, test_predd[i].cpu().detach().numpy(), axis = 0)\n",
    "        \n",
    "from mpl_toolkits import mplot3d\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "# Data for a three-dimensional line\n",
    "zline = np.linspace(0, 15, 1000)\n",
    "xline = np.sin(zline)\n",
    "yline = np.cos(zline)\n",
    "ax.plot3D(test_set_x_5, test_set_y_5, test_set_z_5, 'gray')\n",
    "ax.plot3D(pred[:,0], pred[:,1], pred[:,2], 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
