{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to analyze the gt points' distribution with respect to predicted points location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import interactive\n",
    "interactive(True)\n",
    "%matplotlib qt\n",
    "\n",
    "import scipy.stats\n",
    "\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import my_model\n",
    "from utilities import MyTrainDataSet, MyTestDataSet, load_data_2, load_test_data, min_max_scaling, min_max_scaling_radius, normalize_one, construct_train_valid_tensor, construct_test_tensor, show_statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train = np.load(\"input_tensor.npy\")\n",
    "gt_label = np.load(\"gt_label_tensor.npy\")\n",
    "pd_label = np.load(\"pd_label_tensor.npy\")\n",
    "\n",
    "input_valid_train = np.load(\"input_valid_tensor.npy\")\n",
    "gt_valid_label = np.load(\"gt_valid_label_tensor.npy\")\n",
    "pd_valid_label = np.load(\"pd_valid_label_tensor.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.Tensor(input_train)\n",
    "gt_label_tensor = torch.Tensor(gt_label)\n",
    "pd_label_tensor = torch.Tensor(pd_label)\n",
    "\n",
    "input_valid_tensor = torch.Tensor(input_valid_train)\n",
    "gt_valid_label_tensor = torch.Tensor(gt_valid_label)\n",
    "pd_valid_label_tensor = torch.Tensor(pd_valid_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MDN(nn.Module):\n",
    "    def __init__(self, n_input, n_hidden, n_gaussians):\n",
    "        super(MDN, self).__init__()\n",
    "        self.l_h = nn.Sequential(\n",
    "            nn.Linear(n_input, n_hidden),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.l_pi = nn.Linear(n_hidden, n_gaussians)\n",
    "        \n",
    "        self.l_mu_x = nn.Linear(n_hidden, n_gaussians)\n",
    "        self.l_sigma_x = nn.Linear(n_hidden, n_gaussians)\n",
    "        \n",
    "        self.l_mu_y = nn.Linear(n_hidden, n_gaussians)\n",
    "        self.l_sigma_y = nn.Linear(n_hidden, n_gaussians)\n",
    "        \n",
    "        self.l_mu_z = nn.Linear(n_hidden, n_gaussians)\n",
    "        self.l_sigma_z = nn.Linear(n_hidden, n_gaussians)\n",
    "        \n",
    "        '''\n",
    "        self.l_correlation_x_y = nn.Sequential(\n",
    "            nn.Linear(n_hidden, n_gaussians),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.l_correlation_x_z = nn.Sequential(\n",
    "            nn.Linear(n_hidden, n_gaussians),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.l_correlation_y_z = nn.Sequential(\n",
    "            nn.Linear(n_hidden, n_gaussians),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        '''\n",
    "    def forward(self, x):\n",
    "        h = self.l_h(x)\n",
    "        # print(\"h\", h.shape)\n",
    "        # print(\"h[0]\", h[0, :])\n",
    "        pi = F.softmax(self.l_pi(h), -1)\n",
    "        # print(\"pi\", pi.shape)\n",
    "        # print(\"pi[0]\", pi[0, :])\n",
    "        mu_x = self.l_mu_x(h)\n",
    "        # print(\"mu_x\", pi.shape)\n",
    "        mu_y = self.l_mu_y(h)\n",
    "        # print(\"mu_y\", pi.shape)\n",
    "        mu_z = self.l_mu_z(h)\n",
    "        # print(\"mu_z\", pi.shape)\n",
    "        \n",
    "        # use exp to ensure positive range\n",
    "        sigma_x = torch.exp(self.l_sigma_x(h))\n",
    "        # print(\"sigma_x\", sigma_x.shape)\n",
    "        sigma_y = torch.exp(self.l_sigma_y(h))\n",
    "        # print(\"sigma_y\", sigma_y.shape)\n",
    "        sigma_z = torch.exp(self.l_sigma_z(h))\n",
    "        # print(\"sigma_z\", sigma_z.shape)\n",
    "        '''\n",
    "        # use tanh to ensoure range of (-1, 1)\n",
    "        correlation_x_y = self.l_correlation_x_y(h)\n",
    "        # print(\"correlation_x_y\", pi.shape)\n",
    "        # print(\"correlation_x_y[0]\", correlation_x_y[0, :])\n",
    "        correlation_x_z = self.l_correlation_x_z(h)\n",
    "        # print(\"correlation_x_z\", pi.shape)\n",
    "        # print(\"correlation_x_z[0]\", correlation_x_z[0, :])\n",
    "        correlation_y_z = self.l_correlation_y_z(h)\n",
    "        # print(\"correlation_y_z\", pi.shape)\n",
    "        # print(\"correlation_y_z[0]\", correlation_y_z[0, :])\n",
    "        '''\n",
    "        return pi, mu_x, mu_y, mu_z, sigma_x, sigma_y, sigma_z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mdn_loss_fn(y, pi, mu_x, mu_y, mu_z, sigma_x, sigma_y, sigma_z):\n",
    "    # print(\"mu_x shape\", mu_x.shape)\n",
    "    # mu = torch.stack((mu_x, mu_y, mu_z), 2)\n",
    "    # print(\"mu shape \", mu.shape)\n",
    "    # print(\"mu[0]\", mu[0])\n",
    "    \n",
    "    ##############################################################################\n",
    "    # print(\"sigma x,y,z size\", sigma_x.shape, sigma_y.shape, sigma_z.shape)\n",
    "    \n",
    "    size = y.shape[0]\n",
    "    n_gaussians = pi.shape[1]\n",
    "    # print(\"sample size: \", size)\n",
    "    # print(\"num of gaus: \", n_gaussians)\n",
    "    # print(\"correlation size: \", correlation_x_y.shape)\n",
    "    # build mean matrix\n",
    "    mean = torch.stack((mu_x, mu_y, mu_z), dim=2)\n",
    "    # build covariance matrix with standard trivariate normal distribution\n",
    "    cov = torch.zeros([size, n_gaussians, 3, 3])\n",
    "    cov[:, :, 0, 0] = sigma_x**2\n",
    "    cov[:, :, 1, 1] = sigma_y**2\n",
    "    cov[:, :, 2, 2] = sigma_z**2\n",
    "    \n",
    "    # print(\"mean: \", mean.shape)\n",
    "    '''\n",
    "    print(\"cov: \", cov.shape)\n",
    "    print(\"sigma x\", (sigma_x**2)[0, 0])\n",
    "    print(\"sigma y\", (sigma_y**2)[0, 0])\n",
    "    print(\"sigma z\", (sigma_z**2)[0, 0])\n",
    "    print(\"cov\", cov[0, 0])\n",
    "    print(\"sigma x\", (sigma_x**2)[0, 1])\n",
    "    print(\"sigma y\", (sigma_y**2)[0, 1])\n",
    "    print(\"sigma z\", (sigma_z**2)[0, 1])\n",
    "    print(\"cov\", cov[0, 1])\n",
    "    '''\n",
    "    # print(\"mean is cuda: \", mean.is_cuda)\n",
    "    # print(\" cov is cuda: \", cov.is_cuda)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    w = y[0]**2*(correlation_y_z**2 - 1) +\\\n",
    "        y[1]**2*(correlation_x_z**2 - 1) +\\\n",
    "        y[2]**2*(correlation_x_y**2 - 1) +\\\n",
    "        2*(y[0]*y[:1]*(correlation_x_y - correlation_x_z*correlation_y_z) +\\\n",
    "           y[0]*y[:2]*(correlation_x_z - correlation_x_y*correlation_y_z) +\\\n",
    "           y[1]*y[:2]*(correlation_y_z - correlation_x_y*correlation_x_z))\n",
    "    \n",
    "    return w\n",
    "    '''\n",
    "    '''\n",
    "    cov = torch.Tensor([[sigma_x**2, 0, 0], [0, sigma_y**2, 0], [0, 0, sigma_z**2]])\n",
    "    cov[1, 0] = correlation_x_y*sigma_x*sigma_y\n",
    "    cov[2, 0] = correlation_x_z*sigma_x*sigma_z\n",
    "    cov[2, 1] = correlation_y_z*sigma_y*sigma_z\n",
    "    cov[0, 1] = correlation_x_y*sigma_x*sigma_y\n",
    "    cov[0, 2] = correlation_x_z*sigma_x*sigma_z\n",
    "    cov[1, 2] = correlation_y_z*sigma_y*sigma_z\n",
    "    '''\n",
    "    \n",
    "    # mean: N x n_gaussian x 3\n",
    "    # cov: N x 5 x 3 x 3\n",
    "    m = torch.distributions.multivariate_normal.MultivariateNormal(loc=mean, covariance_matrix=cov)\n",
    "    # expand y to N x n_gaussian x 3\n",
    "    y = y.unsqueeze(1).repeat(1, n_gaussians, 1)\n",
    "    \n",
    "    # print(\"y size\", y.shape) # 14985 x 5 x 3\n",
    "    \n",
    "    # y: [x, y, z]; row: x, y, z; column: N, number of samples\n",
    "    # y: N x 3\n",
    "    # loss: N x 1\n",
    "    # print(y_normal.is_cuda)\n",
    "    likelihood = torch.exp(m.log_prob(y))\n",
    "    \n",
    "    # print(\"likelihood shape: \", likelihood.shape) # 14985 x 5\n",
    "    # print(\"pi shape: \", pi.shape) # 14985 x 5\n",
    "    loss = torch.sum(likelihood * pi, dim=1) # 14985 X 1\n",
    "    '''\n",
    "    for i in range(loss.shape[0]):\n",
    "        if loss[i] > 1.5:\n",
    "            print(\"loss: \", loss[i])\n",
    "            print(\"likelihood: \", likelihood[i])\n",
    "            print(\"mu array  : \", pi[i])\n",
    "            # print(\"likelihood shape: \", likelihood.shape) # 14985 x 5\n",
    "    '''\n",
    "    loss = -torch.log(loss)\n",
    "    return torch.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gaussian = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mdn = MDN(3, n_hidden=20, n_gaussians=n_gaussian)\n",
    "#if torch.cuda.is_available():\n",
    "#    model.cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(model_mdn.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list = []\n",
    "for epoch in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    pi, mu_x, mu_y, mu_z, sigma_x, sigma_y, sigma_z = model_mdn(pd_label_tensor)\n",
    "    loss = mdn_loss_fn(gt_label_tensor, pi, mu_x, mu_y, mu_z, sigma_x, sigma_y, sigma_z)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_list.append(loss.data.item())\n",
    "    \n",
    "    total_valid_loss = 0.0\n",
    "    valid_pred = []\n",
    "    pi_valid, mu_x_valid, mu_y_valid, mu_z_valid, sigma_x_valid, sigma_y_valid, sigma_z_valid = model_mdn(pd_valid_label_tensor)\n",
    "    loss = mdn_loss_fn(gt_valid_label_tensor, pi, mu_x, mu_y, mu_z, sigma_x, sigma_y, sigma_z)\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(\"-------epoch \", epoch, \"-------\")\n",
    "        print(loss.data.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi, mu_x, mu_y, mu_z, sigma_x, sigma_y, sigma_z = model_mdn(pd_label_tensor)\n",
    "\n",
    "size = pi.shape[0]\n",
    "n_gaussians = pi.shape[1]\n",
    "# print(\"sample size: \", size)\n",
    "# print(\"num of gaus: \", n_gaussians)\n",
    "# print(\"correlation size: \", correlation_x_y.shape)\n",
    "# build mean matrix\n",
    "mean = torch.stack((mu_x, mu_y, mu_z), dim=2)\n",
    "# build covariance matrix with standard trivariate normal distribution\n",
    "cov = torch.zeros([size, n_gaussians, 3, 3])\n",
    "cov[:, :, 0, 0] = sigma_x**2\n",
    "cov[:, :, 1, 1] = sigma_y**2\n",
    "cov[:, :, 2, 2] = sigma_z**2\n",
    "\n",
    "m = torch.distributions.multivariate_normal.MultivariateNormal(loc=mean, covariance_matrix=cov)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd = m.rsample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = torch.multinomial(pi, 1).view(-1)\n",
    "PPD = torch.zeros([size, 3])\n",
    "for i in range(pd.shape[0]):\n",
    "    PPD[i, :] = pd[i,k[i],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPD.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPD = PPD.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_x = mu_x.detach().numpy()\n",
    "mu_y = mu_y.detach().numpy()\n",
    "mu_z = mu_z.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(gt_label[:,0], label='gt', linestyle='--')\n",
    "plt.plot(pd_label[:,0], label='pd', linestyle='--')\n",
    "plt.plot(PPD[:,0], label='pd_mdn', linestyle='--')\n",
    "plt.plot(mu_x[:,0], label='mu 1')\n",
    "plt.plot(mu_x[:,1], label='mu 2')\n",
    "# plt.plot(mu_x[:,2], label='mu 3')\n",
    "# plt.plot(mu_x[:,3], label='mu 4')\n",
    "# plt.plot(mu_x[:,4], label='mu 5')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "radius = 0.2\n",
    "density = 40 # sample size alone radius\n",
    "x_center, y_center, z_center = pd_label[index]\n",
    "\n",
    "s_x = np.zeros([density*2 + 1, density*2 + 1, density*2 + 1])\n",
    "s_y = np.zeros([density*2 + 1, density*2 + 1, density*2 + 1])\n",
    "s_z = np.zeros([density*2 + 1, density*2 + 1, density*2 + 1])\n",
    "\n",
    "x_min = x_center - radius\n",
    "y_min = y_center - radius\n",
    "z_min = z_center - radius\n",
    "unit_size = radius/density\n",
    "\n",
    "for i in range(density*2 + 1):\n",
    "    for j in range(density*2 + 1):\n",
    "        for k in range(density*2 + 1):\n",
    "            s_x[i, j, k] = x_min + i*unit_size\n",
    "            s_y[i, j, k] = y_min + j*unit_size\n",
    "            s_z[i, j, k] = z_min + k*unit_size\n",
    "            \n",
    "\n",
    "\n",
    "pi, mu_x, mu_y, mu_z, sigma_x, sigma_y, sigma_z = model_mdn(pd_label_tensor[index])\n",
    "pi = pi.unsqueeze(0)\n",
    "mu_x = mu_x.unsqueeze(0)\n",
    "mu_y = mu_y.unsqueeze(0)\n",
    "mu_z = mu_z.unsqueeze(0)\n",
    "sigma_x = sigma_x.unsqueeze(0)\n",
    "sigma_y = sigma_y.unsqueeze(0)\n",
    "sigma_z = sigma_z.unsqueeze(0)\n",
    "# print(pi.shape)\n",
    "# print(mu_x.shape)\n",
    "# print(mu_y.shape)\n",
    "# print(mu_z.shape)\n",
    "# print(sigma_x.shape)\n",
    "# print(sigma_y.shape)\n",
    "# print(sigma_z.shape)\n",
    "\n",
    "size = pi.shape[0]\n",
    "n_gaussians = pi.shape[1]\n",
    "# build mean matrix\n",
    "mean = torch.stack((mu_x, mu_y, mu_z), dim=2)\n",
    "# print(mean.shape)\n",
    "# build covariance matrix with standard trivariate normal distribution\n",
    "cov = torch.zeros([size, n_gaussians, 3, 3])\n",
    "cov[:, :, 0, 0] = sigma_x**2\n",
    "cov[:, :, 1, 1] = sigma_y**2\n",
    "cov[:, :, 2, 2] = sigma_z**2\n",
    "# print(cov.shape)\n",
    "\n",
    "# mean[0, 0] = -0.18\n",
    "# mean[0, 1] = 0\n",
    "# mean[0, 2] = -0.01\n",
    "\n",
    "normal_3d = torch.distributions.multivariate_normal.MultivariateNormal(loc=mean, covariance_matrix=cov)\n",
    "\n",
    "pdf = np.zeros([density*2 + 1, density*2 + 1, density*2 + 1])\n",
    "for i in range(density*2 + 1):\n",
    "    print(i)\n",
    "    for j in range(density*2 + 1):\n",
    "        for k in range(density*2 + 1):\n",
    "            likelihood = torch.exp(normal_3d.log_prob(torch.tensor([[s_x[i, j, k], s_y[i, j, k], s_z[i, j, k]]])))\n",
    "            # get mixture sum\n",
    "            # pdf[i, j, k] = torch.sum(likelihood * pi, dim=1)\n",
    "            pdf[i, j, k] = likelihood[0, 0]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "radius = 0.2\n",
    "density = 40 # sample size alone radius\n",
    "x_center, y_center, z_center = pd_label[index]\n",
    "\n",
    "s_x = np.zeros([density*2 + 1, density*2 + 1, density*2 + 1])\n",
    "s_y = np.zeros([density*2 + 1, density*2 + 1, density*2 + 1])\n",
    "s_z = np.zeros([density*2 + 1, density*2 + 1, density*2 + 1])\n",
    "\n",
    "x_min = x_center - radius\n",
    "y_min = y_center - radius\n",
    "z_min = z_center - radius\n",
    "unit_size = radius/density\n",
    "\n",
    "for i in range(density*2 + 1):\n",
    "    for j in range(density*2 + 1):\n",
    "        for k in range(density*2 + 1):\n",
    "            s_x[i, j, k] = x_min + i*unit_size\n",
    "            s_y[i, j, k] = y_min + j*unit_size\n",
    "            s_z[i, j, k] = z_min + k*unit_size\n",
    "            \n",
    "\n",
    "\n",
    "pi, mu_x, mu_y, mu_z, sigma_x, sigma_y, sigma_z = model_mdn(pd_label_tensor[index])\n",
    "pi = pi.unsqueeze(0)\n",
    "mu_x = mu_x.unsqueeze(0)\n",
    "mu_y = mu_y.unsqueeze(0)\n",
    "mu_z = mu_z.unsqueeze(0)\n",
    "sigma_x = sigma_x.unsqueeze(0)\n",
    "sigma_y = sigma_y.unsqueeze(0)\n",
    "sigma_z = sigma_z.unsqueeze(0)\n",
    "# print(pi.shape)\n",
    "# print(mu_x.shape)\n",
    "# print(mu_y.shape)\n",
    "# print(mu_z.shape)\n",
    "# print(sigma_x.shape)\n",
    "# print(sigma_y.shape)\n",
    "# print(sigma_z.shape)\n",
    "\n",
    "size = pi.shape[0]\n",
    "n_gaussians = pi.shape[1]\n",
    "# build mean matrix\n",
    "mean = torch.stack((mu_x, mu_y, mu_z), dim=2)\n",
    "# print(mean.shape)\n",
    "# build covariance matrix with standard trivariate normal distribution\n",
    "cov = torch.zeros([size, n_gaussians, 3, 3])\n",
    "cov[:, :, 0, 0] = sigma_x**2\n",
    "cov[:, :, 1, 1] = sigma_y**2\n",
    "cov[:, :, 2, 2] = sigma_z**2\n",
    "# print(cov.shape)\n",
    "\n",
    "# mean[0, 0] = 0.01\n",
    "# mean[0, 1] = 0\n",
    "# mean[0, 2] = -0.01\n",
    "\n",
    "normal_3d = torch.distributions.multivariate_normal.MultivariateNormal(loc=mean, covariance_matrix=cov)\n",
    "\n",
    "pdf_1 = np.zeros([density*2 + 1, density*2 + 1, density*2 + 1])\n",
    "for i in range(density*2 + 1):\n",
    "    print(i)\n",
    "    for j in range(density*2 + 1):\n",
    "        for k in range(density*2 + 1):\n",
    "            likelihood = torch.exp(normal_3d.log_prob(torch.tensor([[s_x[i, j, k], s_y[i, j, k], s_z[i, j, k]]])))\n",
    "            # get mixture sum\n",
    "            # pdf_![i, j, k] = torch.sum(likelihood * pi, dim=1)\n",
    "            pdf_1[i, j, k] = likelihood[0, 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "index = 0\n",
    "radius = 0.2\n",
    "density = 40 # sample size alone radius\n",
    "# radius = 0.01\n",
    "# density = 20 # sample size alone radius\n",
    "x_center, y_center, z_center = pd_label[index]\n",
    "\n",
    "s_x = np.zeros([density*2 + 1, density*2 + 1, density*2 + 1])\n",
    "s_y = np.zeros([density*2 + 1, density*2 + 1, density*2 + 1])\n",
    "s_z = np.zeros([density*2 + 1, density*2 + 1, density*2 + 1])\n",
    "\n",
    "x_min = x_center - radius\n",
    "y_min = y_center - radius\n",
    "z_min = z_center - radius\n",
    "unit_size = radius/density\n",
    "\n",
    "for i in range(density*2 + 1):\n",
    "    for j in range(density*2 + 1):\n",
    "        for k in range(density*2 + 1):\n",
    "            s_x[i, j, k] = x_min + i*unit_size\n",
    "            s_y[i, j, k] = y_min + j*unit_size\n",
    "            s_z[i, j, k] = z_min + k*unit_size\n",
    "            \n",
    "\n",
    "\n",
    "pi, mu_x, mu_y, mu_z, sigma_x, sigma_y, sigma_z = model_mdn(pd_label_tensor[index])\n",
    "pi = pi.unsqueeze(0)\n",
    "mu_x = mu_x.unsqueeze(0)\n",
    "mu_y = mu_y.unsqueeze(0)\n",
    "mu_z = mu_z.unsqueeze(0)\n",
    "sigma_x = sigma_x.unsqueeze(0)\n",
    "sigma_y = sigma_y.unsqueeze(0)\n",
    "sigma_z = sigma_z.unsqueeze(0)\n",
    "# print(pi.shape)\n",
    "# print(mu_x.shape)\n",
    "# print(mu_y.shape)\n",
    "# print(mu_z.shape)\n",
    "# print(sigma_x.shape)\n",
    "# print(sigma_y.shape)dd\n",
    "# print(sigma_z.shape)\n",
    "\n",
    "size = pi.shape[0]\n",
    "n_gaussians = pi.shape[1]\n",
    "# build mean matrix\n",
    "mean = torch.stack((mu_x, mu_y, mu_z), dim=2)\n",
    "# print(mean.shape)\n",
    "# build covariance matrix with standard trivariate normal distribution\n",
    "cov = torch.zeros([size, n_gaussians, 3, 3])\n",
    "cov[:, :, 0, 0] = sigma_x**2\n",
    "cov[:, :, 1, 1] = sigma_y**2\n",
    "cov[:, :, 2, 2] = sigma_z**2\n",
    "# print(cov.shape)\n",
    "\n",
    "# mean[0, 0] = -0.18\n",
    "# mean[0, 1] = 0\n",
    "# mean[0, 2] = -0.01\n",
    "\n",
    "normal_3d = torch.distributions.multivariate_normal.MultivariateNormal(loc=mean, covariance_matrix=cov)\n",
    "\n",
    "        \n",
    "pdf_all = np.zeros([density*2 + 1, density*2 + 1, density*2 + 1])\n",
    "for i in range(density*2 + 1):\n",
    "    print(i)\n",
    "    for j in range(density*2 + 1):\n",
    "        for k in range(density*2 + 1):\n",
    "            likelihood = torch.exp(normal_3d.log_prob(torch.tensor([[s_x[i, j, k], s_y[i, j, k], s_z[i, j, k]]])))\n",
    "            # get mixture sum\n",
    "            pdf_all[i, j, k] = torch.sum(likelihood * pi, dim=1)\n",
    "            # pdf_4[i, j, k] = likelihood[0, 4]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd_label_tensor[0])\n",
    "print(pi[0])\n",
    "print(mu_x[0])\n",
    "print(mu_y[0])\n",
    "print(mu_z[0])\n",
    "print(sigma_x[0])\n",
    "print(sigma_y[0])\n",
    "print(sigma_z[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mayavi import mlab\n",
    "\n",
    "src = mlab.pipeline.scalar_field(pdf)\n",
    "mlab.pipeline.iso_surface(src, contours=[0.1, ], opacity=0.3, color = (0.8,0.0,0.0))\n",
    "# mlab.pipeline.iso_surface(src, contours=[pdf.max()-0.1*pdf.ptp(), ],)\n",
    "\n",
    "src_1 = mlab.pipeline.scalar_field(pdf_1)\n",
    "mlab.pipeline.iso_surface(src_1, contours=[0.1, ], opacity=0.3, color = (0.8,0.0,0.0))\n",
    "# mlab.pipeline.iso_surface(src_1, contours=[pdf_1.max()-0.1*pdf_1.ptp(), ],)\n",
    "\n",
    "# src_half = mlab.pipeline.scalar_field(pdf_half)\n",
    "# mlab.pipeline.iso_surface(src_half, contours=[0.1, ], opacity=0.3, color = (0.0,0.8,0.0))\n",
    "# mlab.pipeline.iso_surface(src, contours=[pdf.max()-0.1*pdf.ptp(), ],)\n",
    "\n",
    "# src_1_half = mlab.pipeline.scalar_field(pdf_1_half)\n",
    "# mlab.pipeline.iso_surface(src_1_half, contours=[0.1, ], opacity=0.3, color = (0.0,0.8,0.0))\n",
    "# mlab.pipeline.iso_surface(src_1, contours=[pdf_1.max()-0.1*pdf_1.ptp(), ],)\n",
    "\n",
    "src_all = mlab.pipeline.scalar_field(pdf_all)\n",
    "mlab.pipeline.iso_surface(src_all, contours=[0.1, ], opacity=0.3, color = (0.0,0.0,0.8))\n",
    "# mlab.pipeline.iso_surface(src_1, contours=[pdf_1.max()-0.1*pdf_1.ptp(), ],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "8.1318e-02 + 3.6224e-01 + 9.2028e-07 + 1.2253e-02 + 1.7447e-06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi.unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ax.scatter(s_x.flatten(), s_y.flatten(), s_z.flatten(), c='r', marker='o')\n",
    "\n",
    "ax.set_xlabel('X Label')\n",
    "ax.set_ylabel('Y Label')\n",
    "ax.set_zlabel('Z Label')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(21):\n",
    "    for j in range(21):\n",
    "        for k in range(21):\n",
    "            s[i, j, k] = torch.exp(normal_3d.log_prob(torch.FloatTensor([i-10, j-10, k-10])))\n",
    "            \n",
    "src = mlab.pipeline.scalar_field(s)\n",
    "mlab.pipeline.iso_surface(src, contours=[s.min()+0.1*s.ptp(), ], opacity=0.3)\n",
    "mlab.pipeline.iso_surface(src, contours=[s.max()-0.1*s.ptp(), ],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    m = torch.distributions.multivariate_normal.MultivariateNormal(loc=mean, covariance_matrix=cov)\n",
    "\n",
    "k = torch.multinomial(pi, 1).view(-1)\n",
    "y_pred = torch.normal(mu, sigma)[np.arange(n_samples), k].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([0.1585, 0.1787, 0.1571, 0.3795, 0.1261])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([0.0165, 0.0245, 0.1137, 2.8152, 0.0082])\n",
    "b = torch.tensor([0.0339, 0.0643, 0.1532, 0.5262, 0.2225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(a*b, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(a*b).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2,3,4],[5,6,7,8],[9,10,11,12]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[:, [1,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = torch.stack((a, b), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[0,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.softmax(a, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.exp(7) / (math.exp(1) + math.exp(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.softmax(a, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = torch.stack((mu_x, mu_y, mu_z), dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w[:, :, 0, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gaussians = 5\n",
    "size = 14000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = e.unsqueeze(0).repeat(n_gaussians, 1, 1).unsqueeze(0).repeat(size, 1, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = e.repeat(5, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = e.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = e.repeat(10, 1, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1,2,3],[4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits import mplot3d\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "# ax.plot3D(test[:,0], test[:,1], test[:,2], 'gray')\n",
    "ax.plot3D(input_tensor[0, :, 0], input_tensor[0, :, 1], input_tensor[0, :, 2], 'gray')\n",
    "ax.scatter(gt_label_tensor[0,0], gt_label_tensor[0,1], gt_label_tensor[0,2], 'green')\n",
    "ax.scatter(pd_label_tensor[0,0], pd_label_tensor[0,1], pd_label_tensor[0,2], 'red')\n",
    "# ax.plot3D(gt_label_tensor[0:2,0], gt_label_tensor[0:2,1], gt_label_tensor[0:2,2], 'green')\n",
    "# ax.plot3D(pd_label_tensor[0:2,0], pd_label_tensor[0:2,1], pd_label_tensor[0:2,2], 'red')\n",
    "\n",
    "ax.set_xlabel('X Label')\n",
    "ax.set_ylabel('Y Label')\n",
    "ax.set_zlabel('Z Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits import mplot3d\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "# ax.plot3D(test[:,0], test[:,1], test[:,2], 'gray')\n",
    "ax.plot3D(input_tensor[:3, 0, 0], input_tensor[:3, 0, 1], input_tensor[:3, 0, 2], 'gray')\n",
    "ax.scatter(input_tensor[:3, 0, 0], input_tensor[:3, 0, 1], input_tensor[:3, 0, 2], c = 'gray')\n",
    "\n",
    "ax.plot3D(input_tensor[2:6, 0, 0], input_tensor[2:6, 0, 1], input_tensor[2:6, 0, 2], 'green')\n",
    "ax.scatter(input_tensor[2:6, 0, 0], input_tensor[2:6, 0, 1], input_tensor[2:6, 0, 2], c = 'green')\n",
    "\n",
    "ax.plot3D(gt_label_tensor[0:3,0], gt_label_tensor[0:3,1], gt_label_tensor[0:3,2], 'black')\n",
    "ax.plot3D(pd_label_tensor[0:3,0], pd_label_tensor[0:3,1], pd_label_tensor[0:3,2], 'red')\n",
    "ax.scatter(pd_label_tensor[0:3,0], pd_label_tensor[0:3,1], pd_label_tensor[0:3,2], c = 'red')\n",
    "\n",
    "ax.set_xlabel('X Label')\n",
    "ax.set_ylabel('Y Label')\n",
    "ax.set_zlabel('Z Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pd = pd_label_tensor[:, 0].reshape(-1,1)\n",
    "y_pd = pd_label_tensor[:, 1].reshape(-1,1)\n",
    "z_pd = pd_label_tensor[:, 2].reshape(-1,1)\n",
    "\n",
    "x_gt = gt_label_tensor[:, 0].reshape(-1,1)\n",
    "y_gt = gt_label_tensor[:, 1].reshape(-1,1)\n",
    "z_gt = gt_label_tensor[:, 2].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_gt = x_gt.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_gt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_gt)\n",
    "plt.plot(x_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply MDN on x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 14985\n",
    "\n",
    "x_data = torch.Tensor(x_pd)\n",
    "y_data = torch.Tensor(x_gt)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(x_data, y_data, alpha=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MDN(nn.Module):\n",
    "    def __init__(self, n_hidden, n_gaussians):\n",
    "        super(MDN, self).__init__()\n",
    "        self.z_h = nn.Sequential(\n",
    "            nn.Linear(1, n_hidden),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.z_pi = nn.Linear(n_hidden, n_gaussians)\n",
    "        self.z_mu = nn.Linear(n_hidden, n_gaussians)\n",
    "        self.z_sigma = nn.Linear(n_hidden, n_gaussians)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z_h = self.z_h(x)\n",
    "        pi = F.softmax(self.z_pi(z_h), -1)\n",
    "        mu = self.z_mu(z_h)\n",
    "        sigma = torch.exp(self.z_sigma(z_h))\n",
    "        return pi, mu, sigma\n",
    "\n",
    "model = MDN(n_hidden=20, n_gaussians=5)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mdn_loss_fn(y, mu, sigma, pi):\n",
    "    m = torch.distributions.Normal(loc=mu, scale=sigma)\n",
    "    loss = torch.exp(m.log_prob(y))\n",
    "    loss = torch.sum(loss * pi, dim=1)\n",
    "    loss = -torch.log(loss)\n",
    "    return torch.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10000):\n",
    "    pi, mu, sigma = model(x_data)\n",
    "    loss = mdn_loss_fn(y_data, mu, sigma, pi)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 1000 == 0:\n",
    "        print(loss.data.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi, mu, sigma = model(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pi.shape)\n",
    "print(mu.shape)\n",
    "print(sigma.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the index of the highest index of the 5 elements in each row\n",
    "k = torch.multinomial(pi, 1).view(-1)\n",
    "y_pred = torch.normal(mu, sigma)[np.arange(n_samples), k].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "# lt.scatter(x_data, y_data, alpha=0.4)\n",
    "# plt.scatter(x_data, y_pred, alpha=0.8, color='red')\n",
    "# plt.scatter(x_test[0], y_pred[0], alpha=0.4, color='yellow')\n",
    "plt.scatter(x_data, mu[:,0].detach(), label='mean 0')\n",
    "plt.scatter(x_data, mu[:,1].detach(), label='mean 1')\n",
    "plt.scatter(x_data, mu[:,2].detach(), label='mean 2')\n",
    "plt.scatter(x_data, mu[:,3].detach(), label='mean 3')\n",
    "plt.scatter(x_data, mu[:,4].detach(), label='mean 4')\n",
    "# plt.plot(x_test.numpy(), mu[:,0].detach().numpy())\n",
    "# plt.scatter(x_data[:20], y_data[:20], alpha=0.4)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = pi.detach().numpy()\n",
    "mu = mu.detach().numpy()\n",
    "sigma = sigma.detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = x_data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.zeros((n_samples, 100))\n",
    "x = np.linspace(-2, 2, 100)\n",
    "\n",
    "for i in range(n_samples):\n",
    "    each = []\n",
    "    for j in range(5):\n",
    "        if (j == 0):\n",
    "            y = [pi[i, j] * ele for ele in scipy.stats.norm.pdf(x, mu[i, j],sigma[i, j])]\n",
    "            each.append(y)\n",
    "            cumulated_y = y\n",
    "        else:\n",
    "            y = [pi[i, j] * ele for ele in scipy.stats.norm.pdf(x, mu[i, j],sigma[i, j])]\n",
    "            each.append(y)\n",
    "            cumulated_y = [p + q for p, q in zip(cumulated_y, y)]\n",
    "    p[i, :] = cumulated_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes(projection='3d')\n",
    "for i in range(0,n_samples):\n",
    "    ax.plot3D([x_data[i, 0]]*100, x, p[i, :])\n",
    "\n",
    "ax.set_xlabel('index')\n",
    "ax.set_ylabel('x')\n",
    "ax.set_zlabel('pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data[0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### apply MDN on 3D projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_1_1 = torch.Tensor([1, 1, 1])\n",
    "mean_1_2 = torch.Tensor([2, 2, 2])\n",
    "mean_1_3 = torch.Tensor([3, 3, 3])\n",
    "mean_1_4 = torch.Tensor([4, 4, 4])\n",
    "mean_1_5 = torch.Tensor([5, 5, 5])\n",
    "\n",
    "mean_2_1 = torch.Tensor([6, 6, 6])\n",
    "mean_2_2 = torch.Tensor([7, 7, 7])\n",
    "mean_2_3 = torch.Tensor([8, 8, 8])\n",
    "mean_2_4 = torch.Tensor([9, 9, 9])\n",
    "mean_2_5 = torch.Tensor([10, 10, 10])\n",
    "\n",
    "sigma_1 = 1\n",
    "sigma_2 = 1\n",
    "sigma_3 = 1\n",
    "cov_1_1 = torch.Tensor([[sigma_1**2, 0, 0], [0, sigma_2**2, 0], [0, 0, sigma_3**2]])\n",
    "rho_1_2 = 0.7\n",
    "rho_2_3 = 0.7\n",
    "rho_1_3 = 0.7\n",
    "cov_1_1[1, 0] = rho_1_2*sigma_1*sigma_2\n",
    "cov_1_1[2, 0] = rho_1_3*sigma_1*sigma_3\n",
    "cov_1_1[2, 1] = rho_2_3*sigma_2*sigma_3\n",
    "cov_1_1[0, 1] = rho_1_2*sigma_1*sigma_2\n",
    "cov_1_1[0, 2] = rho_1_3*sigma_1*sigma_3\n",
    "cov_1_1[1, 2] = rho_2_3*sigma_2*sigma_3\n",
    "\n",
    "sigma_1 = 2\n",
    "sigma_2 = 2\n",
    "sigma_3 = 2\n",
    "cov_1_2 = torch.Tensor([[sigma_1**2, 0, 0], [0, sigma_2**2, 0], [0, 0, sigma_3**2]])\n",
    "rho_1_2 = 0.7\n",
    "rho_2_3 = 0.7\n",
    "rho_1_3 = 0.7\n",
    "cov_1_2[1, 0] = rho_1_2*sigma_1*sigma_2\n",
    "cov_1_2[2, 0] = rho_1_3*sigma_1*sigma_3\n",
    "cov_1_2[2, 1] = rho_2_3*sigma_2*sigma_3\n",
    "cov_1_2[0, 1] = rho_1_2*sigma_1*sigma_2\n",
    "cov_1_2[0, 2] = rho_1_3*sigma_1*sigma_3\n",
    "cov_1_2[1, 2] = rho_2_3*sigma_2*sigma_3\n",
    "                         \n",
    "sigma_1 = 3\n",
    "sigma_2 = 3\n",
    "sigma_3 = 3\n",
    "cov_1_3 = torch.Tensor([[sigma_1**2, 0, 0], [0, sigma_2**2, 0], [0, 0, sigma_3**2]])\n",
    "rho_1_2 = 0.7\n",
    "rho_2_3 = 0.7\n",
    "rho_1_3 = 0.7\n",
    "cov_1_3[1, 0] = rho_1_2*sigma_1*sigma_2\n",
    "cov_1_3[2, 0] = rho_1_3*sigma_1*sigma_3\n",
    "cov_1_3[2, 1] = rho_2_3*sigma_2*sigma_3\n",
    "cov_1_3[0, 1] = rho_1_2*sigma_1*sigma_2\n",
    "cov_1_3[0, 2] = rho_1_3*sigma_1*sigma_3\n",
    "cov_1_3[1, 2] = rho_2_3*sigma_2*sigma_3\n",
    "                         \n",
    "sigma_1 = 4\n",
    "sigma_2 = 4\n",
    "sigma_3 = 4\n",
    "cov_1_4 = torch.Tensor([[sigma_1**2, 0, 0], [0, sigma_2**2, 0], [0, 0, sigma_3**2]])\n",
    "rho_1_2 = 0.7\n",
    "rho_2_3 = 0.7\n",
    "rho_1_3 = 0.7\n",
    "cov_1_4[1, 0] = rho_1_2*sigma_1*sigma_2\n",
    "cov_1_4[2, 0] = rho_1_3*sigma_1*sigma_3\n",
    "cov_1_4[2, 1] = rho_2_3*sigma_2*sigma_3\n",
    "cov_1_4[0, 1] = rho_1_2*sigma_1*sigma_2\n",
    "cov_1_4[0, 2] = rho_1_3*sigma_1*sigma_3\n",
    "cov_1_4[1, 2] = rho_2_3*sigma_2*sigma_3\n",
    "                         \n",
    "sigma_1 = 5\n",
    "sigma_2 = 5\n",
    "sigma_3 = 5\n",
    "cov_1_5 = torch.Tensor([[sigma_1**2, 0, 0], [0, sigma_2**2, 0], [0, 0, sigma_3**2]])\n",
    "rho_1_2 = 0.7\n",
    "rho_2_3 = 0.7\n",
    "rho_1_3 = 0.7\n",
    "cov_1_5[1, 0] = rho_1_2*sigma_1*sigma_2\n",
    "cov_1_5[2, 0] = rho_1_3*sigma_1*sigma_3\n",
    "cov_1_5[2, 1] = rho_2_3*sigma_2*sigma_3\n",
    "cov_1_5[0, 1] = rho_1_2*sigma_1*sigma_2\n",
    "cov_1_5[0, 2] = rho_1_3*sigma_1*sigma_3\n",
    "cov_1_5[1, 2] = rho_2_3*sigma_2*sigma_3\n",
    "                         \n",
    "sigma_1 = 6\n",
    "sigma_2 = 6\n",
    "sigma_3 = 6\n",
    "cov_2_1 = torch.Tensor([[sigma_1**2, 0, 0], [0, sigma_2**2, 0], [0, 0, sigma_3**2]])\n",
    "rho_1_2 = 0.7\n",
    "rho_2_3 = 0.7\n",
    "rho_1_3 = 0.7\n",
    "cov_2_1[1, 0] = rho_1_2*sigma_1*sigma_2\n",
    "cov_2_1[2, 0] = rho_1_3*sigma_1*sigma_3\n",
    "cov_2_1[2, 1] = rho_2_3*sigma_2*sigma_3\n",
    "cov_2_1[0, 1] = rho_1_2*sigma_1*sigma_2\n",
    "cov_2_1[0, 2] = rho_1_3*sigma_1*sigma_3\n",
    "cov_2_1[1, 2] = rho_2_3*sigma_2*sigma_3\n",
    "\n",
    "sigma_1 = 7\n",
    "sigma_2 = 7\n",
    "sigma_3 = 7\n",
    "cov_2_2 = torch.Tensor([[sigma_1**2, 0, 0], [0, sigma_2**2, 0], [0, 0, sigma_3**2]])\n",
    "rho_1_2 = 0.7\n",
    "rho_2_3 = 0.7\n",
    "rho_1_3 = 0.7\n",
    "cov_2_2[1, 0] = rho_1_2*sigma_1*sigma_2\n",
    "cov_2_2[2, 0] = rho_1_3*sigma_1*sigma_3\n",
    "cov_2_2[2, 1] = rho_2_3*sigma_2*sigma_3\n",
    "cov_2_2[0, 1] = rho_1_2*sigma_1*sigma_2\n",
    "cov_2_2[0, 2] = rho_1_3*sigma_1*sigma_3\n",
    "cov_2_2[1, 2] = rho_2_3*sigma_2*sigma_3\n",
    "                         \n",
    "sigma_1 = 8\n",
    "sigma_2 = 8\n",
    "sigma_3 = 8\n",
    "cov_2_3 = torch.Tensor([[sigma_1**2, 0, 0], [0, sigma_2**2, 0], [0, 0, sigma_3**2]])\n",
    "rho_1_2 = 0.7\n",
    "rho_2_3 = 0.7\n",
    "rho_1_3 = 0.7\n",
    "cov_2_3[1, 0] = rho_1_2*sigma_1*sigma_2\n",
    "cov_2_3[2, 0] = rho_1_3*sigma_1*sigma_3\n",
    "cov_2_3[2, 1] = rho_2_3*sigma_2*sigma_3\n",
    "cov_2_3[0, 1] = rho_1_2*sigma_1*sigma_2\n",
    "cov_2_3[0, 2] = rho_1_3*sigma_1*sigma_3\n",
    "cov_2_3[1, 2] = rho_2_3*sigma_2*sigma_3\n",
    "                         \n",
    "sigma_1 = 9\n",
    "sigma_2 = 9\n",
    "sigma_3 = 9\n",
    "cov_2_4 = torch.Tensor([[sigma_1**2, 0, 0], [0, sigma_2**2, 0], [0, 0, sigma_3**2]])\n",
    "rho_1_2 = 0.7\n",
    "rho_2_3 = 0.7\n",
    "rho_1_3 = 0.7\n",
    "cov_2_4[1, 0] = rho_1_2*sigma_1*sigma_2\n",
    "cov_2_4[2, 0] = rho_1_3*sigma_1*sigma_3\n",
    "cov_2_4[2, 1] = rho_2_3*sigma_2*sigma_3\n",
    "cov_2_4[0, 1] = rho_1_2*sigma_1*sigma_2\n",
    "cov_2_4[0, 2] = rho_1_3*sigma_1*sigma_3\n",
    "cov_2_4[1, 2] = rho_2_3*sigma_2*sigma_3\n",
    "                         \n",
    "sigma_1 = 10\n",
    "sigma_2 = 10\n",
    "sigma_3 = 10\n",
    "cov_2_5 = torch.Tensor([[sigma_1**2, 0, 0], [0, sigma_2**2, 0], [0, 0, sigma_3**2]])\n",
    "rho_1_2 = 0.7\n",
    "rho_2_3 = 0.7\n",
    "rho_1_3 = 0.7\n",
    "cov_2_5[1, 0] = rho_1_2*sigma_1*sigma_2\n",
    "cov_2_5[2, 0] = rho_1_3*sigma_1*sigma_3\n",
    "cov_2_5[2, 1] = rho_2_3*sigma_2*sigma_3\n",
    "cov_2_5[0, 1] = rho_1_2*sigma_1*sigma_2\n",
    "cov_2_5[0, 2] = rho_1_3*sigma_1*sigma_3\n",
    "cov_2_5[1, 2] = rho_2_3*sigma_2*sigma_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_1 = torch.stack((mean_1_1, mean_1_2, mean_1_3, mean_1_4, mean_1_5), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_2 = torch.stack((mean_2_1, mean_2_2, mean_2_3, mean_2_4, mean_2_5), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = torch.stack((mean_1, mean_2), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_1 = torch.stack((cov_1_1, cov_1_2, cov_1_3, cov_1_4, cov_1_5), dim=0)\n",
    "cov_2 = torch.stack((cov_2_1, cov_2_2, cov_2_3, cov_2_4, cov_2_5), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = torch.stack((cov_1, cov_2), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_3d = torch.distributions.multivariate_normal.MultivariateNormal(mean, covariance_matrix=cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.Tensor([[1,1,1], [2,2,2], [3,3,3], [4,4,4], [5,5,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.stack((y, y), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.exp(normal_3d.log_prob(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_3d = torch.distributions.multivariate_normal.MultivariateNormal(mean_1, covariance_matrix=cov_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.Tensor([[1,1,1], [2,2,2], [3,3,3], [4,4,4], [5,5,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_1 = mean_1.unsqueeze(0)\n",
    "cov_1 = cov_1.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_3d = torch.distributions.multivariate_normal.MultivariateNormal(mean_1, covariance_matrix=cov_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.Tensor([[1,1,1], [2,2,2], [3,3,3], [4,4,4], [5,5,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.exp(normal_3d.log_prob(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.Tensor([[1,2,3]])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "torch.exp(normal_3d.log_prob(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.Tensor([[1, 1, 1],[1, 2, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = torch.exp(normal_3d.log_prob(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = torch.stack((cov, cov_1), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_3d = torch.distributions.multivariate_normal.MultivariateNormal(mean, covariance_matrix=cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.Tensor([[1, 1, 1],[1, 2, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.exp(normal_3d.log_prob(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.Tensor([[1,1,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.exp(normal_3d.log_prob(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = torch.zeros(3)\n",
    "sigma_1 = 4\n",
    "sigma_2 = 4\n",
    "sigma_3 = 4\n",
    "cov = torch.Tensor([[sigma_1**2, 0, 0], [0, sigma_2**2, 0], [0, 0, sigma_3**2]])\n",
    "rho_1_2 = 0.7\n",
    "rho_2_3 = 0.7\n",
    "rho_1_3 = 0.7\n",
    "cov[1, 0] = rho_1_2*sigma_1*sigma_2\n",
    "cov[2, 0] = rho_1_3*sigma_1*sigma_3\n",
    "cov[2, 1] = rho_2_3*sigma_2*sigma_3\n",
    "cov[0, 1] = rho_1_2*sigma_1*sigma_2\n",
    "cov[0, 2] = rho_1_3*sigma_1*sigma_3\n",
    "cov[1, 2] = rho_2_3*sigma_2*sigma_3\n",
    "normal_3d = torch.distributions.multivariate_normal.MultivariateNormal(mean, covariance_matrix=cov)\n",
    "\n",
    "y = torch.Tensor([[1, 2, 3]])\n",
    "torch.exp(normal_3d.log_prob(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = torch.zeros(3)\n",
    "sigma_1 = 2\n",
    "sigma_2 = 2\n",
    "sigma_3 = 2\n",
    "cov_1 = torch.Tensor([[sigma_1**2, 0, 0], [0, sigma_2**2, 0], [0, 0, sigma_3**2]])\n",
    "rho_1_2 = 0.7\n",
    "rho_2_3 = 0.7\n",
    "rho_1_3 = 0.7\n",
    "cov_1[1, 0] = rho_1_2*sigma_1*sigma_2\n",
    "cov_1[2, 0] = rho_1_3*sigma_1*sigma_3\n",
    "cov_1[2, 1] = rho_2_3*sigma_2*sigma_3\n",
    "cov_1[0, 1] = rho_1_2*sigma_1*sigma_2\n",
    "cov_1[0, 2] = rho_1_3*sigma_1*sigma_3\n",
    "cov_1[1, 2] = rho_2_3*sigma_2*sigma_3\n",
    "normal_3d = torch.distributions.multivariate_normal.MultivariateNormal(mean, covariance_matrix=cov_1)\n",
    "\n",
    "y = torch.Tensor([[1, 2, 3]])\n",
    "torch.exp(normal_3d.log_prob(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mayavi import mlab\n",
    "\n",
    "s = np.zeros([21, 21, 21])\n",
    "for i in range(21):\n",
    "    for j in range(21):\n",
    "        for k in range(21):\n",
    "            s[i, j, k] = torch.exp(normal_3d.log_prob(torch.FloatTensor([i-10, j-10, k-10])))\n",
    "            \n",
    "src = mlab.pipeline.scalar_field(s)\n",
    "mlab.pipeline.iso_surface(src, contours=[s.min()+0.1*s.ptp(), ], opacity=0.3)\n",
    "mlab.pipeline.iso_surface(src, contours=[s.max()-0.1*s.ptp(), ],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 10, 1001)\n",
    "y = np.linspace(0, 10, 1001)\n",
    "z = np.linspace(0, 10, 1001)\n",
    "x_p = x + 0.5 * np.random.randn(1001)\n",
    "y_p = y + 0.5 * np.random.randn(1001)\n",
    "z_p = z + 0.5 * np.random.randn(1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter(x, y, z)\n",
    "ax.scatter(x_p, y_p, z_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MDN(nn.Module):\n",
    "    def __init__(self, n_input, n_hidden, n_gaussians):\n",
    "        super(MDN, self).__init__()\n",
    "        self.l_h = nn.Sequential(\n",
    "            nn.Linear(n_input, n_hidden),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.l_pi = nn.Linear(n_hidden, n_gaussians)\n",
    "        \n",
    "        self.l_mu_x = nn.Linear(n_hidden, n_gaussians)\n",
    "        self.l_sigma_x = nn.Linear(n_hidden, n_gaussians)\n",
    "        \n",
    "        self.l_mu_y = nn.Linear(n_hidden, n_gaussians)\n",
    "        self.l_sigma_y = nn.Linear(n_hidden, n_gaussians)\n",
    "        \n",
    "        self.l_mu_z = nn.Linear(n_hidden, n_gaussians)\n",
    "        self.l_sigma_z = nn.Linear(n_hidden, n_gaussians)\n",
    "        \n",
    "        # self.l_correlation_x_y = nn.Linear(n_hidden, n_gaussians)\n",
    "        # self.l_correlation_x_z = nn.Linear(n_hidden, n_gaussians)\n",
    "        # self.l_correlation_y_z = nn.Linear(n_hidden, n_gaussians)\n",
    "        \n",
    "        self.l_correlation_x_y = nn.Sequential(\n",
    "            nn.Linear(n_hidden, n_gaussians),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.l_correlation_x_z = nn.Sequential(\n",
    "            nn.Linear(n_hidden, n_gaussians),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.l_correlation_y_z = nn.Sequential(\n",
    "            nn.Linear(n_hidden, n_gaussians),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h = self.l_h(x)\n",
    "        # print(\"h\", h.shape)\n",
    "        # print(\"h[0]\", h[0, :])\n",
    "        pi = F.softmax(self.l_pi(h), -1)\n",
    "        # print(\"pi\", pi.shape)\n",
    "        # print(\"pi[0]\", pi[0, :])\n",
    "        mu_x = self.l_mu_x(h)\n",
    "        # print(\"mu_x\", pi.shape)\n",
    "        mu_y = self.l_mu_y(h)\n",
    "        # print(\"mu_y\", pi.shape)\n",
    "        mu_z = self.l_mu_z(h)\n",
    "        # print(\"mu_z\", pi.shape)\n",
    "        \n",
    "        # use exp to ensure positive range\n",
    "        sigma_x = torch.exp(self.l_sigma_x(h))\n",
    "        # print(\"sigma_x\", pi.shape)\n",
    "        sigma_y = torch.exp(self.l_sigma_y(h))\n",
    "        # print(\"sigma_y\", pi.shape)\n",
    "        sigma_z = torch.exp(self.l_sigma_z(h))\n",
    "        # print(\"sigma_z\", pi.shape)\n",
    "        \n",
    "        # use tanh to ensoure range of (-1, 1)\n",
    "        correlation_x_y = self.l_correlation_x_y(h)\n",
    "        # print(\"correlation_x_y\", pi.shape)\n",
    "        # print(\"correlation_x_y[0]\", correlation_x_y[0, :])\n",
    "        correlation_x_z = self.l_correlation_x_z(h)\n",
    "        # print(\"correlation_x_z\", pi.shape)\n",
    "        # print(\"correlation_x_z[0]\", correlation_x_z[0, :])\n",
    "        correlation_y_z = self.l_correlation_y_z(h)\n",
    "        # print(\"correlation_y_z\", pi.shape)\n",
    "        # print(\"correlation_y_z[0]\", correlation_y_z[0, :])\n",
    "        \n",
    "        return pi, mu_x, mu_y, mu_z, sigma_x, sigma_y, sigma_z, correlation_x_y, correlation_x_z, correlation_y_z\n",
    "\n",
    "model = MDN(3, n_hidden=20, n_gaussians=5)\n",
    "#if torch.cuda.is_available():\n",
    "#    model.cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mdn_loss_fn(y, pi, mu_x, mu_y, mu_z, sigma_x, sigma_y, sigma_z, correlation_x_y, correlation_x_z, correlation_y_z):\n",
    "    # print(\"mu_x shape\", mu_x.shape)\n",
    "    # mu = torch.stack((mu_x, mu_y, mu_z), 2)\n",
    "    # print(\"mu shape \", mu.shape)\n",
    "    # print(\"mu[0]\", mu[0])\n",
    "    \n",
    "    ##############################################################################\n",
    "    \n",
    "    size = y.shape[0]\n",
    "    n_gaussians = pi.shape[1]\n",
    "    # print(\"sample size: \", size)\n",
    "    # print(\"num of gaus: \", n_gaussians)\n",
    "    # print(\"correlation size: \", correlation_x_y.shape)\n",
    "    # build mean matrix\n",
    "    mean = torch.zeros([size, n_gaussians, 3])\n",
    "    # build covariance matrix with standard trivariate normal distribution\n",
    "    cov = torch.ones([size, n_gaussians, 3, 3])\n",
    "    cov[:, :, 0, 1] = correlation_x_y\n",
    "    cov[:, :, 1, 0] = correlation_x_y\n",
    "    cov[:, :, 0, 2] = correlation_x_z\n",
    "    cov[:, :, 2, 0] = correlation_x_z\n",
    "    cov[:, :, 1, 2] = correlation_y_z\n",
    "    cov[:, :, 2, 1] = correlation_y_z\n",
    "    \n",
    "    print(\"mean: \", mean.shape)\n",
    "    print(\"cov: \", cov.shape)\n",
    "    \n",
    "    print(\"mean is cuda: \", mean.is_cuda)\n",
    "    print(\" cov is cuda: \", cov.is_cuda)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    w = y[0]**2*(correlation_y_z**2 - 1) +\\\n",
    "        y[1]**2*(correlation_x_z**2 - 1) +\\\n",
    "        y[2]**2*(correlation_x_y**2 - 1) +\\\n",
    "        2*(y[0]*y[:1]*(correlation_x_y - correlation_x_z*correlation_y_z) +\\\n",
    "           y[0]*y[:2]*(correlation_x_z - correlation_x_y*correlation_y_z) +\\\n",
    "           y[1]*y[:2]*(correlation_y_z - correlation_x_y*correlation_x_z))\n",
    "    \n",
    "    return w\n",
    "    '''\n",
    "    '''\n",
    "    cov = torch.Tensor([[sigma_x**2, 0, 0], [0, sigma_y**2, 0], [0, 0, sigma_z**2]])\n",
    "    cov[1, 0] = correlation_x_y*sigma_x*sigma_y\n",
    "    cov[2, 0] = correlation_x_z*sigma_x*sigma_z\n",
    "    cov[2, 1] = correlation_y_z*sigma_y*sigma_z\n",
    "    cov[0, 1] = correlation_x_y*sigma_x*sigma_y\n",
    "    cov[0, 2] = correlation_x_z*sigma_x*sigma_z\n",
    "    cov[1, 2] = correlation_y_z*sigma_y*sigma_z\n",
    "    '''\n",
    "    m = torch.distributions.multivariate_normal.MultivariateNormal(loc=mean, covariance_matrix=cov)\n",
    "    # normalize input y\n",
    "    y_repeat = y.unsqueeze(1).repeat(1, n_gaussians, 1)\n",
    "    # print(y_repeat.shape)\n",
    "    # print(y_repeat[0])\n",
    "    mu_all = torch.stack((mu_x, mu_y, mu_z), dim = 2)\n",
    "    print(\"mu_all shape: \", mu_all.shape)\n",
    "    y_sub = y_repeat - mu_all\n",
    "    print(\"y_sub shape\", y_sub.shape)\n",
    "    sigma_all = torch.stack((sigma_x, sigma_y, sigma_z), dim = 2)\n",
    "    print(\"sigma\", sigma_x.shape)\n",
    "    print(\"sigma all\", sigma_all.shape)\n",
    "    \n",
    "    y_normal = torch.div(y_sub, sigma_all)\n",
    "    \n",
    "    print(\"y_normal size\", y_normal.shape)\n",
    "    \n",
    "    # y: [x, y, z]; row: x, y, z; column: N, number of samples\n",
    "    # y: N x 3\n",
    "    # loss: N x 1\n",
    "    print(y_normal.is_cuda)\n",
    "    loss = torch.exp(m.log_prob(y_normal))\n",
    "    print(\"loss shape: \", loss.shape)\n",
    "    print(\"pi shape: \", pi.shape)\n",
    "    loss = torch.sum(loss * pi, dim=1)\n",
    "    loss = -torch.log(loss)\n",
    "    return torch.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1):\n",
    "    pi, mu_x, mu_y, mu_z, sigma_x, sigma_y, sigma_z, correlation_x_y, correlation_x_z, correlation_y_z = model(pd_label_tensor)\n",
    "    loss = mdn_loss_fn(gt_label_tensor, pi, mu_x, mu_y, mu_z, sigma_x, sigma_y, sigma_z, correlation_x_y, correlation_x_z, correlation_y_z)\n",
    "    # optimizer.zero_grad()\n",
    "    # loss.backward()\n",
    "    # optimizer.step()\n",
    "    # if epoch % 1000 == 0:\n",
    "    #     print(loss.data.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.rand(2,3)\n",
    "print(t)\n",
    "tr = t.repeat(2, 3)\n",
    "print(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.Tensor([[1,2],[4,5],[7,8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.Tensor([[7,8],[6,4],[1,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(a*b, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt[0,0,0] = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t[0, 0] = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_y_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.2939**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.square(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.square(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits import mplot3d\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot3D(gt_label_tensor[:,0], gt_label_tensor[:,1], gt_label_tensor[:,2], 'gray')\n",
    "ax.plot3D(pd_label_tensor[:,0], pd_label_tensor[:,1], pd_label_tensor[:,2], 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits import mplot3d\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot3D(pd_label_tensor[:,0], pd_label_tensor[:,1], pd_label_tensor[:,2], 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(gt_label_tensor[:,2])\n",
    "plt.plot(pd_label_tensor[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1_loss = []\n",
    "for i in range(1, 11):\n",
    "    window_size = i\n",
    "    PATH = \"model/with_early_stop_after_400/model_w_\" + str(i) + \".pt\"\n",
    "\n",
    "    test_set_x_1, test_set_y_1, test_set_z_1 = load_test_data('../../../../performance_test/data/test/test_1.csv')\n",
    "    test_set_x_2, test_set_y_2, test_set_z_2 = load_test_data('../../../../performance_test/data/test/test_2.csv')\n",
    "    test_set_x_3, test_set_y_3, test_set_z_3 = load_test_data('../../../../performance_test/data/test/test_3.csv')\n",
    "    test_set_x_4, test_set_y_4, test_set_z_4 = load_test_data('../../../../performance_test/data/test/test_4.csv')\n",
    "    test_set_x_5, test_set_y_5, test_set_z_5 = load_test_data('../../../../performance_test/data/test/test_5.csv')\n",
    "\n",
    "    # do min-max-scaling for each test data set\n",
    "    show_statistic(test_set_x_1)\n",
    "    min_max_scaling(test_set_x_1)\n",
    "    show_statistic(test_set_x_1)\n",
    "    min_max_scaling(test_set_x_2)\n",
    "    min_max_scaling(test_set_x_3)\n",
    "    min_max_scaling(test_set_x_4)\n",
    "    min_max_scaling(test_set_x_5)\n",
    "\n",
    "    min_max_scaling(test_set_y_1)\n",
    "    min_max_scaling(test_set_y_2)\n",
    "    min_max_scaling(test_set_y_3)\n",
    "    min_max_scaling(test_set_y_4)\n",
    "    min_max_scaling(test_set_y_5)\n",
    "\n",
    "    min_max_scaling(test_set_z_1)\n",
    "    min_max_scaling(test_set_z_2)\n",
    "    min_max_scaling(test_set_z_3)\n",
    "    min_max_scaling(test_set_z_4)\n",
    "    min_max_scaling(test_set_z_5)\n",
    "\n",
    "\n",
    "    show_statistic(test_set_x_1)\n",
    "    # do normalization on x of validation test set\n",
    "    normalize_one(test_set_x_1, x_mean, x_std)\n",
    "    show_statistic(test_set_x_1)\n",
    "    normalize_one(test_set_x_2, x_mean, x_std)\n",
    "    normalize_one(test_set_x_3, x_mean, x_std)\n",
    "    normalize_one(test_set_x_4, x_mean, x_std)\n",
    "    normalize_one(test_set_x_5, x_mean, x_std)\n",
    "    # do normalization on y of validation test set\n",
    "    normalize_one(test_set_y_1, y_mean, y_std)\n",
    "    normalize_one(test_set_y_2, y_mean, y_std)\n",
    "    normalize_one(test_set_y_3, y_mean, y_std)\n",
    "    normalize_one(test_set_y_4, y_mean, y_std)\n",
    "    normalize_one(test_set_y_5, y_mean, y_std)\n",
    "    # do normalization on z of validation test set\n",
    "    normalize_one(test_set_z_1, z_mean, z_std)\n",
    "    normalize_one(test_set_z_2, z_mean, z_std)\n",
    "    normalize_one(test_set_z_3, z_mean, z_std)\n",
    "    normalize_one(test_set_z_4, z_mean, z_std)\n",
    "    normalize_one(test_set_z_5, z_mean, z_std)\n",
    "    # show_statistic(train_set_x_1)\n",
    "\n",
    "\n",
    "    test_dataset_1, test_label_1 = construct_test_tensor(test_set_x_1,\n",
    "                                                         test_set_y_1,\n",
    "                                                         test_set_z_1,\n",
    "                                                         window_size)\n",
    "    test_dataset_2, test_label_2 = construct_test_tensor(test_set_x_2,\n",
    "                                                         test_set_y_2,\n",
    "                                                         test_set_z_2,\n",
    "                                                         window_size)\n",
    "    test_dataset_3, test_label_3 = construct_test_tensor(test_set_x_3,\n",
    "                                                         test_set_y_3,\n",
    "                                                         test_set_z_3,\n",
    "                                                         window_size)\n",
    "    test_dataset_4, test_label_4 = construct_test_tensor(test_set_x_4,\n",
    "                                                         test_set_y_4,\n",
    "                                                         test_set_z_4,\n",
    "                                                         window_size)\n",
    "    test_dataset_5, test_label_5 = construct_test_tensor(test_set_x_5,\n",
    "                                                         test_set_y_5,\n",
    "                                                         test_set_z_5,\n",
    "                                                         window_size)\n",
    "\n",
    "    test_set_1 = MyTestDataSet(test_dataset_1, test_label_1)\n",
    "    test_set_2 = MyTestDataSet(test_dataset_2, test_label_2)\n",
    "    test_set_3 = MyTestDataSet(test_dataset_3, test_label_3)\n",
    "    test_set_4 = MyTestDataSet(test_dataset_4, test_label_4)\n",
    "    test_set_5 = MyTestDataSet(test_dataset_5, test_label_5)\n",
    "    print(len(test_set_1))\n",
    "    print(len(test_set_2))\n",
    "    print(len(test_set_3))\n",
    "    print(len(test_set_4))\n",
    "    print(len(test_set_5))\n",
    "    show_statistic(test_set_x_1)\n",
    "    show_statistic(test_set_x_2)\n",
    "    show_statistic(test_set_x_3)\n",
    "    show_statistic(test_set_x_4)\n",
    "    show_statistic(test_set_x_5)\n",
    "\n",
    "\n",
    "    batch_size = 650\n",
    "    test_loader_1 = DataLoader(test_set_1, batch_size=batch_size, num_workers=0) # dont shuffle test data for using continous trajectory later on\n",
    "    # test_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    test_loader_2 = DataLoader(test_set_2, batch_size=batch_size, num_workers=0) # dont shuffle test data for using continous trajectory later on\n",
    "    # test_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    test_loader_3 = DataLoader(test_set_3, batch_size=batch_size, num_workers=0) # dont shuffle test data for using continous trajectory later on\n",
    "    # test_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    test_loader_4 = DataLoader(test_set_4, batch_size=batch_size, num_workers=0) # dont shuffle test data for using continous trajectory later on\n",
    "    # test_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    test_loader_5 = DataLoader(test_set_5, batch_size=batch_size, num_workers=0) # dont shuffle test data for using continous trajectory later on\n",
    "    # test_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    \n",
    "    input_dim = 3\n",
    "    hidden_dim = 100\n",
    "    layer_dim = 1\n",
    "    output_dim = 3\n",
    "\n",
    "    load_model = my_model.LSTMModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "    load_model.load_state_dict(torch.load(PATH))\n",
    "    load_model.eval()\n",
    "    # mmodel = torch.load(PATH)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        load_model.cuda()\n",
    "\n",
    "    # get test results\n",
    "    seq_dim = window_size\n",
    "    input_dim = 3\n",
    "    # test_seq = []\n",
    "    test_predd = []\n",
    "    # test_gt = []\n",
    "    total_test_loss = 0.0\n",
    "    test_batch = 0\n",
    "    for i, (seqs, labels) in enumerate(test_loader_1):\n",
    "        if torch.cuda.is_available():\n",
    "            seqs = Variable(seqs.view(-1, seq_dim, input_dim).cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "        else:\n",
    "            seqs = Variable(seqs.view(-1, seq_dim, input_dim))\n",
    "\n",
    "        outputs = load_model(seqs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        total_test_loss += loss.data.item()\n",
    "        test_predd.append(outputs)\n",
    "        test_batch = i + 1\n",
    "\n",
    "    print(total_test_loss/test_batch)\n",
    "    test_1_loss.append(total_test_loss/te    input_dim = 3\n",
    "    hidden_dim = 100\n",
    "    layer_dim = 1\n",
    "    output_dim = 3\n",
    "\n",
    "    load_model = my_model.LSTMModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "    load_model.load_state_dict(torch.load(PATH))\n",
    "    load_model.eval()\n",
    "    # mmodel = torch.load(PATH)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        load_model.cuda()\n",
    "\n",
    "    # get test results\n",
    "    seq_dim = window_size\n",
    "    input_dim = 3\n",
    "    # test_seq = []\n",
    "    test_predd = []\n",
    "    # test_gt = []\n",
    "    total_test_loss = 0.0\n",
    "    test_batch = 0\n",
    "    for i, (seqs, labels) in enumerate(test_loader_1):\n",
    "        if torch.cuda.is_available():\n",
    "            seqs = Variable(seqs.view(-1, seq_dim, input_dim).cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "        else:\n",
    "            seqs = Variable(seqs.view(-1, seq_dim, input_dim))\n",
    "\n",
    "        outputs = load_model(seqs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        total_test_loss += loss.data.item()\n",
    "        test_predd.append(outputs)\n",
    "        test_batch = i + 1\n",
    "\n",
    "    print(total_test_loss/test_batch)st_batch)\n",
    "\n",
    "    for i in range(len(test_predd)):\n",
    "        if (i == 0):\n",
    "            pred = test_predd[i].cpu().detach().numpy()\n",
    "        else:\n",
    "            pred = np.append(pred, test_predd[i].cpu().detach().numpy(), axis = 0)\n",
    "\n",
    "    from mpl_toolkits import mplot3d\n",
    "    fig = plt.figure()\n",
    "    ax = plt.axes(projection='3d')\n",
    "\n",
    "    # Data for a three-dimensional line\n",
    "    zline = np.linspace(0, 15, 1000)\n",
    "    xline = np.sin(zline)\n",
    "    yline = np.cos(zline)\n",
    "    ax.plot3D(test_set_x_1, test_set_y_1, test_set_z_1, 'gray')\n",
    "    ax.plot3D(pred[:,0], pred[:,1], pred[:,2], 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find window size 6 is optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
    "\n",
    "x_pos = [i for i, _ in enumerate(x)]\n",
    "\n",
    "# plt.bar(x_pos, test_1_loss)\n",
    "plt.bar(x_pos, test_1_loss, color=['tab:blue',\n",
    "                                   'tab:blue',\n",
    "                                   'tab:blue',\n",
    "                                   'tab:blue',\n",
    "                                   'tab:blue',\n",
    "                                   'tab:green',\n",
    "                                   'tab:blue',\n",
    "                                   'tab:blue',\n",
    "                                   'tab:blue',\n",
    "                                   'tab:blue'], zorder = 3)\n",
    "\n",
    "plt.grid(zorder=0)\n",
    "\n",
    "plt.xlabel(\"Input window size\", fontsize=14)\n",
    "plt.ylabel(\"MSE loss\", fontsize=14)\n",
    "plt.xticks(x_pos, x)\n",
    "\n",
    "plt.ylim([0.017,0.0255])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot result without normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_3_loss = []\n",
    "for i in range(1, 11):\n",
    "    window_size = i\n",
    "    PATH = \"model_v3/with_early_stop_after_400_without_normalization/model_w_\" + str(i) + \".pt\"\n",
    "\n",
    "    test_set_x_1, test_set_y_1, test_set_z_1 = load_test_data('../../../../performance_test/data/test/test_1.csv')\n",
    "    test_set_x_2, test_set_y_2, test_set_z_2 = load_test_data('../../../../performance_test/data/test/test_2.csv')\n",
    "    test_set_x_3, test_set_y_3, test_set_z_3 = load_test_data('../../../../performance_test/data/test/test_3.csv')\n",
    "    test_set_x_4, test_set_y_4, test_set_z_4 = load_test_data('../../../../performance_test/data/test/test_4.csv')\n",
    "    test_set_x_5, test_set_y_5, test_set_z_5 = load_test_data('../../../../performance_test/data/test/test_5.csv')\n",
    "\n",
    "    '''\n",
    "    # do min-max-scaling for each test data set\n",
    "    show_statistic(test_set_x_1)\n",
    "    min_max_scaling(test_set_x_1)\n",
    "    show_statistic(test_set_x_1)\n",
    "    min_max_scaling(test_set_x_2)\n",
    "    min_max_scaling(test_set_x_3)\n",
    "    min_max_scaling(test_set_x_4)\n",
    "    min_max_scaling(test_set_x_5)\n",
    "\n",
    "    min_max_scaling(test_set_y_1)\n",
    "    min_max_scaling(test_set_y_2)\n",
    "    min_max_scaling(test_set_y_3)\n",
    "    min_max_scaling(test_set_y_4)\n",
    "    min_max_scaling(test_set_y_5)\n",
    "\n",
    "    min_max_scaling(test_set_z_1)\n",
    "    min_max_scaling(test_set_z_2)\n",
    "    min_max_scaling(test_set_z_3)\n",
    "    min_max_scaling(test_set_z_4)\n",
    "    min_max_scaling(test_set_z_5)\n",
    "    '''\n",
    "    '''\n",
    "    show_statistic(test_set_x_1)\n",
    "    # do normalization on x of validation test set\n",
    "    normalize_one(test_set_x_1, x_mean, x_std)\n",
    "    show_statistic(test_set_x_1)\n",
    "    normalize_one(test_set_x_2, x_mean, x_std)\n",
    "    normalize_one(test_set_x_3, x_mean, x_std)\n",
    "    normalize_one(test_set_x_4, x_mean, x_std)\n",
    "    normalize_one(test_set_x_5, x_mean, x_std)\n",
    "    # do normalization on y of validation test set\n",
    "    normalize_one(test_set_y_1, y_mean, y_std)\n",
    "    normalize_one(test_set_y_2, y_mean, y_std)\n",
    "    normalize_one(test_set_y_3, y_mean, y_std)\n",
    "    normalize_one(test_set_y_4, y_mean, y_std)\n",
    "    normalize_one(test_set_y_5, y_mean, y_std)\n",
    "    # do normalization on z of validation test set\n",
    "    normalize_one(test_set_z_1, z_mean, z_std)\n",
    "    normalize_one(test_set_z_2, z_mean, z_std)\n",
    "    normalize_one(test_set_z_3, z_mean, z_std)\n",
    "    normalize_one(test_set_z_4, z_mean, z_std)\n",
    "    normalize_one(test_set_z_5, z_mean, z_std)\n",
    "    # show_statistic(train_set_x_1)\n",
    "    '''\n",
    "\n",
    "    test_dataset_1, test_label_1 = construct_test_tensor(test_set_x_1,\n",
    "                                                         test_set_y_1,\n",
    "                                                         test_set_z_1,\n",
    "                                                         window_size)\n",
    "    test_dataset_2, test_label_2 = construct_test_tensor(test_set_x_2,\n",
    "                                                         test_set_y_2,\n",
    "                                                         test_set_z_2,\n",
    "                                                         window_size)\n",
    "    test_dataset_3, test_label_3 = construct_test_tensor(test_set_x_3,\n",
    "                                                         test_set_y_3,\n",
    "                                                         test_set_z_3,\n",
    "                                                         window_size)\n",
    "    test_dataset_4, test_label_4 = construct_test_tensor(test_set_x_4,\n",
    "                                                         test_set_y_4,\n",
    "                                                         test_set_z_4,\n",
    "                                                         window_size)\n",
    "    test_dataset_5, test_label_5 = construct_test_tensor(test_set_x_5,\n",
    "                                                         test_set_y_5,\n",
    "                                                         test_set_z_5,\n",
    "                                                         window_size)\n",
    "\n",
    "    test_set_1 = MyTestDataSet(test_dataset_1, test_label_1)\n",
    "    test_set_2 = MyTestDataSet(test_dataset_2, test_label_2)\n",
    "    test_set_3 = MyTestDataSet(test_dataset_3, test_label_3)\n",
    "    test_set_4 = MyTestDataSet(test_dataset_4, test_label_4)\n",
    "    test_set_5 = MyTestDataSet(test_dataset_5, test_label_5)\n",
    "    print(len(test_set_1))\n",
    "    print(len(test_set_2))\n",
    "    print(len(test_set_3))\n",
    "    print(len(test_set_4))\n",
    "    print(len(test_set_5))\n",
    "    show_statistic(test_set_x_1)\n",
    "    show_statistic(test_set_x_2)\n",
    "    show_statistic(test_set_x_3)\n",
    "    show_statistic(test_set_x_4)\n",
    "    show_statistic(test_set_x_5)\n",
    "\n",
    "\n",
    "    batch_size = 650\n",
    "    test_loader_1 = DataLoader(test_set_1, batch_size=batch_size, num_workers=0) # dont shuffle test data for using continous trajectory later on\n",
    "    # test_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    test_loader_2 = DataLoader(test_set_2, batch_size=batch_size, num_workers=0) # dont shuffle test data for using continous trajectory later on\n",
    "    # test_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    test_loader_3 = DataLoader(test_set_3, batch_size=batch_size, num_workers=0) # dont shuffle test data for using continous trajectory later on\n",
    "    # test_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    test_loader_4 = DataLoader(test_set_4, batch_size=batch_size, num_workers=0) # dont shuffle test data for using continous trajectory later on\n",
    "    # test_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    test_loader_5 = DataLoader(test_set_5, batch_size=batch_size, num_workers=0) # dont shuffle test data for using continous trajectory later on\n",
    "    # test_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    \n",
    "    input_dim = 3\n",
    "    hidden_dim = 100\n",
    "    layer_dim = 1\n",
    "    output_dim = 3\n",
    "\n",
    "    load_model = my_model.LSTMModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "    load_model.load_state_dict(torch.load(PATH))\n",
    "    load_model.eval()\n",
    "    # mmodel = torch.load(PATH)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        load_model.cuda()\n",
    "\n",
    "    # get test results\n",
    "    seq_dim = window_size\n",
    "    input_dim = 3\n",
    "    # test_seq = []\n",
    "    test_predd = []\n",
    "    # test_gt = []\n",
    "    total_test_loss = 0.0\n",
    "    test_batch = 0\n",
    "    for i, (seqs, labels) in enumerate(test_loader_3):\n",
    "        if torch.cuda.is_available():\n",
    "            seqs = Variable(seqs.view(-1, seq_dim, input_dim).cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "        else:\n",
    "            seqs = Variable(seqs.view(-1, seq_dim, input_dim))\n",
    "\n",
    "        outputs = load_model(seqs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        total_test_loss += loss.data.item()\n",
    "        test_predd.append(outputs)\n",
    "        test_batch = i + 1\n",
    "\n",
    "    print(total_test_loss/test_batch)\n",
    "    test_3_loss.append(total_test_loss/test_batch)\n",
    "\n",
    "    for i in range(len(test_predd)):\n",
    "        if (i == 0):\n",
    "            pred = test_predd[i].cpu().detach().numpy()\n",
    "        else:\n",
    "            pred = np.append(pred, test_predd[i].cpu().detach().numpy(), axis = 0)\n",
    "\n",
    "    from mpl_toolkits import mplot3d\n",
    "    fig = plt.figure()\n",
    "    ax = plt.axes(projection='3d')\n",
    "\n",
    "    # Data for a three-dimensional line\n",
    "    zline = np.linspace(0, 15, 1000)\n",
    "    xline = np.sin(zline)\n",
    "    yline = np.cos(zline)\n",
    "    ax.plot3D(test_set_x_3, test_set_y_3, test_set_z_3, 'gray')\n",
    "    ax.plot3D(pred[:,0], pred[:,1], pred[:,2], 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_3_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(test_3_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
    "\n",
    "x_pos = [i for i, _ in enumerate(x)]\n",
    "\n",
    "# plt.bar(x_pos, test_1_loss)\n",
    "plt.bar(x_pos, test_3_loss, color=['tab:blue',\n",
    "                                   'tab:blue',\n",
    "                                   'tab:green',\n",
    "                                   'tab:blue',\n",
    "                                   'tab:blue',\n",
    "                                   'tab:blue',\n",
    "                                   'tab:blue',\n",
    "                                   'tab:blue',\n",
    "                                   'tab:blue',\n",
    "                                   'tab:blue'], zorder = 3)\n",
    "\n",
    "plt.grid(zorder=0)\n",
    "\n",
    "plt.xlabel(\"Input Window Size\", fontsize=12)\n",
    "plt.ylabel(\"MSE Loss\", fontsize=12)\n",
    "plt.xticks(x_pos, x)\n",
    "\n",
    "# plt.ylim([0.017,0.0255])\n",
    "plt.ylim([0.025,0.039])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
