{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the model of using differnet window size, compare their results on valid dataset\n",
    "#    test dataset without any preprocessing, no scaling and no normalization\n",
    "# decide which window size is the optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import interactive\n",
    "interactive(True)\n",
    "%matplotlib qt\n",
    "\n",
    "\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import my_model\n",
    "from utilities import MyTrainDataSet, MyTestDataSet, load_data_2, load_test_data, min_max_scaling, normalize_one, construct_train_valid_tensor, construct_test_tensor, show_statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_test_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a4e07786e17b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mPATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"model_v3/with_early_stop_after_400_without_normalization/model_w_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".pt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtest_set_x_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set_y_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set_z_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_test_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../../../../performance_test/data/test/test_1.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mtest_set_x_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set_y_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set_z_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_test_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../../../../performance_test/data/test/test_2.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtest_set_x_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set_y_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set_z_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_test_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../../../../performance_test/data/test/test_3.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_test_data' is not defined"
     ]
    }
   ],
   "source": [
    "test_3_loss = []\n",
    "for i in range(1, 11):\n",
    "    window_size = i\n",
    "    PATH = \"model_v3/with_early_stop_after_400_without_normalization/model_w_\" + str(i) + \".pt\"\n",
    "\n",
    "    test_set_x_1, test_set_y_1, test_set_z_1 = load_test_data('../../../../performance_test/data/test/test_1.csv')\n",
    "    test_set_x_2, test_set_y_2, test_set_z_2 = load_test_data('../../../../performance_test/data/test/test_2.csv')\n",
    "    test_set_x_3, test_set_y_3, test_set_z_3 = load_test_data('../../../../performance_test/data/test/test_3.csv')\n",
    "    test_set_x_4, test_set_y_4, test_set_z_4 = load_test_data('../../../../performance_test/data/test/test_4.csv')\n",
    "    test_set_x_5, test_set_y_5, test_set_z_5 = load_test_data('../../../../performance_test/data/test/test_5.csv')\n",
    "\n",
    "    '''\n",
    "    # do min-max-scaling for each test data set\n",
    "    show_statistic(test_set_x_1)\n",
    "    min_max_scaling(test_set_x_1)\n",
    "    show_statistic(test_set_x_1)\n",
    "    min_max_scaling(test_set_x_2)\n",
    "    min_max_scaling(test_set_x_3)\n",
    "    min_max_scaling(test_set_x_4)\n",
    "    min_max_scaling(test_set_x_5)\n",
    "\n",
    "    min_max_scaling(test_set_y_1)\n",
    "    min_max_scaling(test_set_y_2)\n",
    "    min_max_scaling(test_set_y_3)\n",
    "    min_max_scaling(test_set_y_4)\n",
    "    min_max_scaling(test_set_y_5)\n",
    "\n",
    "    min_max_scaling(test_set_z_1)\n",
    "    min_max_scaling(test_set_z_2)\n",
    "    min_max_scaling(test_set_z_3)\n",
    "    min_max_scaling(test_set_z_4)\n",
    "    min_max_scaling(test_set_z_5)\n",
    "    '''\n",
    "    '''\n",
    "    show_statistic(test_set_x_1)\n",
    "    # do normalization on x of validation test set\n",
    "    normalize_one(test_set_x_1, x_mean, x_std)\n",
    "    show_statistic(test_set_x_1)\n",
    "    normalize_one(test_set_x_2, x_mean, x_std)\n",
    "    normalize_one(test_set_x_3, x_mean, x_std)\n",
    "    normalize_one(test_set_x_4, x_mean, x_std)\n",
    "    normalize_one(test_set_x_5, x_mean, x_std)\n",
    "    # do normalization on y of validation test set\n",
    "    normalize_one(test_set_y_1, y_mean, y_std)\n",
    "    normalize_one(test_set_y_2, y_mean, y_std)\n",
    "    normalize_one(test_set_y_3, y_mean, y_std)\n",
    "    normalize_one(test_set_y_4, y_mean, y_std)\n",
    "    normalize_one(test_set_y_5, y_mean, y_std)\n",
    "    # do normalization on z of validation test set\n",
    "    normalize_one(test_set_z_1, z_mean, z_std)\n",
    "    normalize_one(test_set_z_2, z_mean, z_std)\n",
    "    normalize_one(test_set_z_3, z_mean, z_std)\n",
    "    normalize_one(test_set_z_4, z_mean, z_std)\n",
    "    normalize_one(test_set_z_5, z_mean, z_std)\n",
    "    # show_statistic(train_set_x_1)\n",
    "    '''\n",
    "\n",
    "    test_dataset_1, test_label_1 = construct_test_tensor(test_set_x_1,\n",
    "                                                         test_set_y_1,\n",
    "                                                         test_set_z_1,\n",
    "                                                         window_size)\n",
    "    test_dataset_2, test_label_2 = construct_test_tensor(test_set_x_2,\n",
    "                                                         test_set_y_2,\n",
    "                                                         test_set_z_2,\n",
    "                                                         window_size)\n",
    "    test_dataset_3, test_label_3 = construct_test_tensor(test_set_x_3,\n",
    "                                                         test_set_y_3,\n",
    "                                                         test_set_z_3,\n",
    "                                                         window_size)\n",
    "    test_dataset_4, test_label_4 = construct_test_tensor(test_set_x_4,\n",
    "                                                         test_set_y_4,\n",
    "                                                         test_set_z_4,\n",
    "                                                         window_size)\n",
    "    test_dataset_5, test_label_5 = construct_test_tensor(test_set_x_5,\n",
    "                                                         test_set_y_5,\n",
    "                                                         test_set_z_5,\n",
    "                                                         window_size)\n",
    "\n",
    "    test_set_1 = MyTestDataSet(test_dataset_1, test_label_1)\n",
    "    test_set_2 = MyTestDataSet(test_dataset_2, test_label_2)\n",
    "    test_set_3 = MyTestDataSet(test_dataset_3, test_label_3)\n",
    "    test_set_4 = MyTestDataSet(test_dataset_4, test_label_4)\n",
    "    test_set_5 = MyTestDataSet(test_dataset_5, test_label_5)\n",
    "    print(len(test_set_1))\n",
    "    print(len(test_set_2))\n",
    "    print(len(test_set_3))\n",
    "    print(len(test_set_4))\n",
    "    print(len(test_set_5))\n",
    "    show_statistic(test_set_x_1)\n",
    "    show_statistic(test_set_x_2)\n",
    "    show_statistic(test_set_x_3)\n",
    "    show_statistic(test_set_x_4)\n",
    "    show_statistic(test_set_x_5)\n",
    "\n",
    "\n",
    "    batch_size = 650\n",
    "    test_loader_1 = DataLoader(test_set_1, batch_size=batch_size, num_workers=0) # dont shuffle test data for using continous trajectory later on\n",
    "    # test_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    test_loader_2 = DataLoader(test_set_2, batch_size=batch_size, num_workers=0) # dont shuffle test data for using continous trajectory later on\n",
    "    # test_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    test_loader_3 = DataLoader(test_set_3, batch_size=batch_size, num_workers=0) # dont shuffle test data for using continous trajectory later on\n",
    "    # test_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    test_loader_4 = DataLoader(test_set_4, batch_size=batch_size, num_workers=0) # dont shuffle test data for using continous trajectory later on\n",
    "    # test_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    test_loader_5 = DataLoader(test_set_5, batch_size=batch_size, num_workers=0) # dont shuffle test data for using continous trajectory later on\n",
    "    # test_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    \n",
    "    input_dim = 3\n",
    "    hidden_dim = 100\n",
    "    layer_dim = 1\n",
    "    output_dim = 3\n",
    "\n",
    "    load_model = my_model.LSTMModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "    load_model.load_state_dict(torch.load(PATH))\n",
    "    load_model.eval()\n",
    "    # mmodel = torch.load(PATH)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        load_model.cuda()\n",
    "\n",
    "    # get test results\n",
    "    seq_dim = window_size\n",
    "    input_dim = 3\n",
    "    # test_seq = []\n",
    "    test_predd = []\n",
    "    # test_gt = []\n",
    "    total_test_loss = 0.0\n",
    "    test_batch = 0\n",
    "    for i, (seqs, labels) in enumerate(test_loader_3):\n",
    "        if torch.cuda.is_available():\n",
    "            seqs = Variable(seqs.view(-1, seq_dim, input_dim).cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "        else:\n",
    "            seqs = Variable(seqs.view(-1, seq_dim, input_dim))\n",
    "\n",
    "        outputs = load_model(seqs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        total_test_loss += loss.data.item()\n",
    "        test_predd.append(outputs)\n",
    "        test_batch = i + 1\n",
    "\n",
    "    print(total_test_loss/test_batch)\n",
    "    test_3_loss.append(total_test_loss/test_batch)\n",
    "\n",
    "    for i in range(len(test_predd)):\n",
    "        if (i == 0):\n",
    "            pred = test_predd[i].cpu().detach().numpy()\n",
    "        else:\n",
    "            pred = np.append(pred, test_predd[i].cpu().detach().numpy(), axis = 0)\n",
    "\n",
    "    from mpl_toolkits import mplot3d\n",
    "    fig = plt.figure()\n",
    "    ax = plt.axes(projection='3d')\n",
    "\n",
    "    # Data for a three-dimensional line\n",
    "    zline = np.linspace(0, 15, 1000)\n",
    "    xline = np.sin(zline)\n",
    "    yline = np.cos(zline)\n",
    "    ax.plot3D(test_set_x_3, test_set_y_3, test_set_z_3, 'gray')\n",
    "    ax.plot3D(pred[:,0], pred[:,1], pred[:,2], 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.03818032145500183,\n",
       " 0.02740023471415043,\n",
       " 0.026449186727404594,\n",
       " 0.026836641132831573,\n",
       " 0.026785902678966522,\n",
       " 0.02710924670100212,\n",
       " 0.027639009058475494,\n",
       " 0.02746979147195816,\n",
       " 0.027946196496486664,\n",
       " 0.028636211529374123]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_3_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.026449186727404594"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(test_3_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.025, 0.039)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
    "\n",
    "x_pos = [i for i, _ in enumerate(x)]\n",
    "\n",
    "# plt.bar(x_pos, test_1_loss)\n",
    "plt.bar(x_pos, test_3_loss, color=['tab:blue',\n",
    "                                   'tab:blue',\n",
    "                                   'tab:green',\n",
    "                                   'tab:blue',\n",
    "                                   'tab:blue',\n",
    "                                   'tab:blue',\n",
    "                                   'tab:blue',\n",
    "                                   'tab:blue',\n",
    "                                   'tab:blue',\n",
    "                                   'tab:blue'], zorder = 3)\n",
    "\n",
    "plt.grid(zorder=0)\n",
    "\n",
    "plt.xlabel(\"Input Window Size\", fontsize=12)\n",
    "plt.ylabel(\"MSE Loss\", fontsize=12)\n",
    "plt.xticks(x_pos, x)\n",
    "\n",
    "# plt.ylim([0.017,0.0255])\n",
    "plt.ylim([0.025,0.039])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
